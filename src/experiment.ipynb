{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# import warnings\n",
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtubeCSV = pd.read_csv('./../data/youtube_data/youtube_finalmerge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "viemoCSV = pd.read_csv('./../data/viemo_data/viemo_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtubeCSV['Label'] = 'YouTube'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "viemoCSV['Label'] = 'viemo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdf = youtubeCSV.add(viemoCSV)\n",
    "pcap_data = pd.concat([youtubeCSV, viemoCSV], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Time</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Length</th>\n",
       "      <th>Info</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Syrotech_8e:b1:98</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>0xfffa</td>\n",
       "      <td>60</td>\n",
       "      <td>Ethernet II</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.042970</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1514</td>\n",
       "      <td>61871  &gt;  443 [ACK] Seq=1 Ack=1 Win=8196 Len=1...</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1514</td>\n",
       "      <td>61871  &gt;  443 [ACK] Seq=1461 Ack=1 Win=8196 Le...</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TLSv1.2</td>\n",
       "      <td>686</td>\n",
       "      <td>Application Data</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.042975</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1514</td>\n",
       "      <td>[TCP Out-Of-Order] 61871  &gt;  443 [ACK] Seq=1 A...</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721847</th>\n",
       "      <td>1721848</td>\n",
       "      <td>72468.453355</td>\n",
       "      <td>192.168.152.133</td>\n",
       "      <td>162.247.243.30</td>\n",
       "      <td>TCP</td>\n",
       "      <td>54</td>\n",
       "      <td>43944  &gt;  443 [FIN, ACK] Seq=91183 Ack=3378 Wi...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721848</th>\n",
       "      <td>1721849</td>\n",
       "      <td>72468.453431</td>\n",
       "      <td>162.247.243.30</td>\n",
       "      <td>192.168.152.133</td>\n",
       "      <td>TCP</td>\n",
       "      <td>60</td>\n",
       "      <td>443  &gt;  43944 [ACK] Seq=3378 Ack=91184 Win=642...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721849</th>\n",
       "      <td>1721850</td>\n",
       "      <td>72468.455805</td>\n",
       "      <td>192.168.152.1</td>\n",
       "      <td>224.0.0.22</td>\n",
       "      <td>IGMPv3</td>\n",
       "      <td>60</td>\n",
       "      <td>Membership Report / Leave group 224.168.100.1</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721850</th>\n",
       "      <td>1721851</td>\n",
       "      <td>72468.502061</td>\n",
       "      <td>192.168.152.1</td>\n",
       "      <td>224.0.0.22</td>\n",
       "      <td>IGMPv3</td>\n",
       "      <td>60</td>\n",
       "      <td>Membership Report / Join group 224.168.100.1 f...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721851</th>\n",
       "      <td>1721852</td>\n",
       "      <td>72468.609610</td>\n",
       "      <td>192.168.152.1</td>\n",
       "      <td>224.0.0.22</td>\n",
       "      <td>IGMPv3</td>\n",
       "      <td>60</td>\n",
       "      <td>Membership Report / Join group 224.168.100.1 f...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2454807 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             No.          Time             Source      Destination Protocol  \\\n",
       "0              1      0.000000  Syrotech_8e:b1:98        Broadcast   0xfffa   \n",
       "1              2      0.042970       192.168.1.35  172.217.160.238      TCP   \n",
       "2              3      0.042974       192.168.1.35  172.217.160.238      TCP   \n",
       "3              4      0.042974       192.168.1.35  172.217.160.238  TLSv1.2   \n",
       "4              5      0.042975       192.168.1.35  172.217.160.238      TCP   \n",
       "...          ...           ...                ...              ...      ...   \n",
       "1721847  1721848  72468.453355    192.168.152.133   162.247.243.30      TCP   \n",
       "1721848  1721849  72468.453431     162.247.243.30  192.168.152.133      TCP   \n",
       "1721849  1721850  72468.455805      192.168.152.1       224.0.0.22   IGMPv3   \n",
       "1721850  1721851  72468.502061      192.168.152.1       224.0.0.22   IGMPv3   \n",
       "1721851  1721852  72468.609610      192.168.152.1       224.0.0.22   IGMPv3   \n",
       "\n",
       "         Length                                               Info    Label  \n",
       "0            60                                        Ethernet II  YouTube  \n",
       "1          1514  61871  >  443 [ACK] Seq=1 Ack=1 Win=8196 Len=1...  YouTube  \n",
       "2          1514  61871  >  443 [ACK] Seq=1461 Ack=1 Win=8196 Le...  YouTube  \n",
       "3           686                                   Application Data  YouTube  \n",
       "4          1514  [TCP Out-Of-Order] 61871  >  443 [ACK] Seq=1 A...  YouTube  \n",
       "...         ...                                                ...      ...  \n",
       "1721847      54  43944  >  443 [FIN, ACK] Seq=91183 Ack=3378 Wi...    viemo  \n",
       "1721848      60  443  >  43944 [ACK] Seq=3378 Ack=91184 Win=642...    viemo  \n",
       "1721849      60      Membership Report / Leave group 224.168.100.1    viemo  \n",
       "1721850      60  Membership Report / Join group 224.168.100.1 f...    viemo  \n",
       "1721851      60  Membership Report / Join group 224.168.100.1 f...    viemo  \n",
       "\n",
       "[2454807 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1721852 entries, 0 to 1721851\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   No.          int64  \n",
      " 1   Time         float64\n",
      " 2   Source       object \n",
      " 3   Destination  object \n",
      " 4   Protocol     object \n",
      " 5   Length       int64  \n",
      " 6   Info         object \n",
      " 7   Label        object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 105.1+ MB\n"
     ]
    }
   ],
   "source": [
    "viemoCSV.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2454807 entries, 0 to 1721851\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   No.          int64  \n",
      " 1   Time         float64\n",
      " 2   Source       object \n",
      " 3   Destination  object \n",
      " 4   Protocol     object \n",
      " 5   Length       int64  \n",
      " 6   Info         object \n",
      " 7   Label        object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 168.6+ MB\n"
     ]
    }
   ],
   "source": [
    "pcap_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>No.</th>\n",
       "      <th>Time</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Length</th>\n",
       "      <th>Info</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Syrotech_8e:b1:98</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>0xfffa</td>\n",
       "      <td>60</td>\n",
       "      <td>Ethernet II</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.042970</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1514</td>\n",
       "      <td>61871  &gt;  443 [ACK] Seq=1 Ack=1 Win=8196 Len=1...</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1514</td>\n",
       "      <td>61871  &gt;  443 [ACK] Seq=1461 Ack=1 Win=8196 Le...</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TLSv1.2</td>\n",
       "      <td>686</td>\n",
       "      <td>Application Data</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.042975</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1514</td>\n",
       "      <td>[TCP Out-Of-Order] 61871  &gt;  443 [ACK] Seq=1 A...</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454802</th>\n",
       "      <td>1721847</td>\n",
       "      <td>1721848</td>\n",
       "      <td>72468.453355</td>\n",
       "      <td>192.168.152.133</td>\n",
       "      <td>162.247.243.30</td>\n",
       "      <td>TCP</td>\n",
       "      <td>54</td>\n",
       "      <td>43944  &gt;  443 [FIN, ACK] Seq=91183 Ack=3378 Wi...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454803</th>\n",
       "      <td>1721848</td>\n",
       "      <td>1721849</td>\n",
       "      <td>72468.453431</td>\n",
       "      <td>162.247.243.30</td>\n",
       "      <td>192.168.152.133</td>\n",
       "      <td>TCP</td>\n",
       "      <td>60</td>\n",
       "      <td>443  &gt;  43944 [ACK] Seq=3378 Ack=91184 Win=642...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454804</th>\n",
       "      <td>1721849</td>\n",
       "      <td>1721850</td>\n",
       "      <td>72468.455805</td>\n",
       "      <td>192.168.152.1</td>\n",
       "      <td>224.0.0.22</td>\n",
       "      <td>IGMPv3</td>\n",
       "      <td>60</td>\n",
       "      <td>Membership Report / Leave group 224.168.100.1</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454805</th>\n",
       "      <td>1721850</td>\n",
       "      <td>1721851</td>\n",
       "      <td>72468.502061</td>\n",
       "      <td>192.168.152.1</td>\n",
       "      <td>224.0.0.22</td>\n",
       "      <td>IGMPv3</td>\n",
       "      <td>60</td>\n",
       "      <td>Membership Report / Join group 224.168.100.1 f...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2454806</th>\n",
       "      <td>1721851</td>\n",
       "      <td>1721852</td>\n",
       "      <td>72468.609610</td>\n",
       "      <td>192.168.152.1</td>\n",
       "      <td>224.0.0.22</td>\n",
       "      <td>IGMPv3</td>\n",
       "      <td>60</td>\n",
       "      <td>Membership Report / Join group 224.168.100.1 f...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2454807 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index      No.          Time             Source      Destination  \\\n",
       "0              0        1      0.000000  Syrotech_8e:b1:98        Broadcast   \n",
       "1              1        2      0.042970       192.168.1.35  172.217.160.238   \n",
       "2              2        3      0.042974       192.168.1.35  172.217.160.238   \n",
       "3              3        4      0.042974       192.168.1.35  172.217.160.238   \n",
       "4              4        5      0.042975       192.168.1.35  172.217.160.238   \n",
       "...          ...      ...           ...                ...              ...   \n",
       "2454802  1721847  1721848  72468.453355    192.168.152.133   162.247.243.30   \n",
       "2454803  1721848  1721849  72468.453431     162.247.243.30  192.168.152.133   \n",
       "2454804  1721849  1721850  72468.455805      192.168.152.1       224.0.0.22   \n",
       "2454805  1721850  1721851  72468.502061      192.168.152.1       224.0.0.22   \n",
       "2454806  1721851  1721852  72468.609610      192.168.152.1       224.0.0.22   \n",
       "\n",
       "        Protocol  Length                                               Info  \\\n",
       "0         0xfffa      60                                        Ethernet II   \n",
       "1            TCP    1514  61871  >  443 [ACK] Seq=1 Ack=1 Win=8196 Len=1...   \n",
       "2            TCP    1514  61871  >  443 [ACK] Seq=1461 Ack=1 Win=8196 Le...   \n",
       "3        TLSv1.2     686                                   Application Data   \n",
       "4            TCP    1514  [TCP Out-Of-Order] 61871  >  443 [ACK] Seq=1 A...   \n",
       "...          ...     ...                                                ...   \n",
       "2454802      TCP      54  43944  >  443 [FIN, ACK] Seq=91183 Ack=3378 Wi...   \n",
       "2454803      TCP      60  443  >  43944 [ACK] Seq=3378 Ack=91184 Win=642...   \n",
       "2454804   IGMPv3      60      Membership Report / Leave group 224.168.100.1   \n",
       "2454805   IGMPv3      60  Membership Report / Join group 224.168.100.1 f...   \n",
       "2454806   IGMPv3      60  Membership Report / Join group 224.168.100.1 f...   \n",
       "\n",
       "           Label  \n",
       "0        YouTube  \n",
       "1        YouTube  \n",
       "2        YouTube  \n",
       "3        YouTube  \n",
       "4        YouTube  \n",
       "...          ...  \n",
       "2454802    viemo  \n",
       "2454803    viemo  \n",
       "2454804    viemo  \n",
       "2454805    viemo  \n",
       "2454806    viemo  \n",
       "\n",
       "[2454807 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcap_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2454807 entries, 0 to 1721851\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   No.          int64  \n",
      " 1   Time         float64\n",
      " 2   Source       object \n",
      " 3   Destination  object \n",
      " 4   Protocol     object \n",
      " 5   Length       int64  \n",
      " 6   Info         object \n",
      " 7   Label        object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 168.6+ MB\n"
     ]
    }
   ],
   "source": [
    "pcap_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>Time</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Length</th>\n",
       "      <th>Info</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Syrotech_8e:b1:98</td>\n",
       "      <td>Broadcast</td>\n",
       "      <td>0xfffa</td>\n",
       "      <td>60</td>\n",
       "      <td>Ethernet II</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.042970</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1514</td>\n",
       "      <td>61871  &gt;  443 [ACK] Seq=1 Ack=1 Win=8196 Len=1...</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1514</td>\n",
       "      <td>61871  &gt;  443 [ACK] Seq=1461 Ack=1 Win=8196 Le...</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TLSv1.2</td>\n",
       "      <td>686</td>\n",
       "      <td>Application Data</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.042975</td>\n",
       "      <td>192.168.1.35</td>\n",
       "      <td>172.217.160.238</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1514</td>\n",
       "      <td>[TCP Out-Of-Order] 61871  &gt;  443 [ACK] Seq=1 A...</td>\n",
       "      <td>YouTube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721847</th>\n",
       "      <td>1721848</td>\n",
       "      <td>72468.453355</td>\n",
       "      <td>192.168.152.133</td>\n",
       "      <td>162.247.243.30</td>\n",
       "      <td>TCP</td>\n",
       "      <td>54</td>\n",
       "      <td>43944  &gt;  443 [FIN, ACK] Seq=91183 Ack=3378 Wi...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721848</th>\n",
       "      <td>1721849</td>\n",
       "      <td>72468.453431</td>\n",
       "      <td>162.247.243.30</td>\n",
       "      <td>192.168.152.133</td>\n",
       "      <td>TCP</td>\n",
       "      <td>60</td>\n",
       "      <td>443  &gt;  43944 [ACK] Seq=3378 Ack=91184 Win=642...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721849</th>\n",
       "      <td>1721850</td>\n",
       "      <td>72468.455805</td>\n",
       "      <td>192.168.152.1</td>\n",
       "      <td>224.0.0.22</td>\n",
       "      <td>IGMPv3</td>\n",
       "      <td>60</td>\n",
       "      <td>Membership Report / Leave group 224.168.100.1</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721850</th>\n",
       "      <td>1721851</td>\n",
       "      <td>72468.502061</td>\n",
       "      <td>192.168.152.1</td>\n",
       "      <td>224.0.0.22</td>\n",
       "      <td>IGMPv3</td>\n",
       "      <td>60</td>\n",
       "      <td>Membership Report / Join group 224.168.100.1 f...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721851</th>\n",
       "      <td>1721852</td>\n",
       "      <td>72468.609610</td>\n",
       "      <td>192.168.152.1</td>\n",
       "      <td>224.0.0.22</td>\n",
       "      <td>IGMPv3</td>\n",
       "      <td>60</td>\n",
       "      <td>Membership Report / Join group 224.168.100.1 f...</td>\n",
       "      <td>viemo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2454807 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             No.          Time             Source      Destination Protocol  \\\n",
       "0              1      0.000000  Syrotech_8e:b1:98        Broadcast   0xfffa   \n",
       "1              2      0.042970       192.168.1.35  172.217.160.238      TCP   \n",
       "2              3      0.042974       192.168.1.35  172.217.160.238      TCP   \n",
       "3              4      0.042974       192.168.1.35  172.217.160.238  TLSv1.2   \n",
       "4              5      0.042975       192.168.1.35  172.217.160.238      TCP   \n",
       "...          ...           ...                ...              ...      ...   \n",
       "1721847  1721848  72468.453355    192.168.152.133   162.247.243.30      TCP   \n",
       "1721848  1721849  72468.453431     162.247.243.30  192.168.152.133      TCP   \n",
       "1721849  1721850  72468.455805      192.168.152.1       224.0.0.22   IGMPv3   \n",
       "1721850  1721851  72468.502061      192.168.152.1       224.0.0.22   IGMPv3   \n",
       "1721851  1721852  72468.609610      192.168.152.1       224.0.0.22   IGMPv3   \n",
       "\n",
       "         Length                                               Info    Label  \n",
       "0            60                                        Ethernet II  YouTube  \n",
       "1          1514  61871  >  443 [ACK] Seq=1 Ack=1 Win=8196 Len=1...  YouTube  \n",
       "2          1514  61871  >  443 [ACK] Seq=1461 Ack=1 Win=8196 Le...  YouTube  \n",
       "3           686                                   Application Data  YouTube  \n",
       "4          1514  [TCP Out-Of-Order] 61871  >  443 [ACK] Seq=1 A...  YouTube  \n",
       "...         ...                                                ...      ...  \n",
       "1721847      54  43944  >  443 [FIN, ACK] Seq=91183 Ack=3378 Wi...    viemo  \n",
       "1721848      60  443  >  43944 [ACK] Seq=3378 Ack=91184 Win=642...    viemo  \n",
       "1721849      60      Membership Report / Leave group 224.168.100.1    viemo  \n",
       "1721850      60  Membership Report / Join group 224.168.100.1 f...    viemo  \n",
       "1721851      60  Membership Report / Join group 224.168.100.1 f...    viemo  \n",
       "\n",
       "[2454807 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcap_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getBurstSeries(pcap_data): \n",
    "    # pcap_data = pd.read_csv('./../../youtube_data/youtube_finalmerge.csv')\n",
    "    #pcap_data = pd.read_csv(filePath)\n",
    "    print(pcap_data.shape)\n",
    "    pcap_data.head()\n",
    "    print(pcap_data.info())\n",
    "    # Filter TCP flows\n",
    "    tcp_flows = pcap_data[pcap_data['Protocol'] == 'TCP']\n",
    "\n",
    "\n",
    "    # Group TCP flows by source and destination\n",
    "    grouped_flows = tcp_flows.groupby(['Source', 'Destination'])\n",
    "\n",
    "        # Function to calculate bytes per second (BPS), packets per second (PPS), and average packet length (PLEN)\n",
    "    def calculate_features(flow):\n",
    "        time_diff = flow['Time'].diff().fillna(0)  # Time difference between packets\n",
    "        byte_diff = flow['Length'].diff().fillna(0)  # Byte difference between packets\n",
    "        \n",
    "        # Bytes per second (BPS)\n",
    "\n",
    "        flow['BPS'] = byte_diff / time_diff \n",
    "        # Replace NaN and inf with zeros in BPS\n",
    "        flow['BPS'].replace([np.nan, np.inf], 0, inplace=True)\n",
    "        \n",
    "        # Packets per second (PPS)\n",
    "        flow['PPS'] = 1 / time_diff \n",
    "\n",
    "        # Replace NaN and inf with zeros in PPS\n",
    "        flow['PPS'].replace([np.nan, np.inf], 0, inplace=True)\n",
    "        \n",
    "        # Average packet length (PLEN)\n",
    "        flow['PLEN'] = byte_diff / flow['PPS']\n",
    "        flow['PLEN'].replace([np.nan, np.inf], 0, inplace=True)        \n",
    "        \n",
    "\n",
    "        flow['Label'] = flow['Label'].apply(lambda x: 1 if x == 'YouTube' else 2)\n",
    "\n",
    "        \n",
    "        return flow\n",
    "\n",
    "    processed_flows = grouped_flows.apply(calculate_features)\n",
    "    processed_flows = processed_flows.drop(columns=['No.', 'Source', 'Destination', 'Protocol', 'Info'])\n",
    "    processed_flows.set_index('Time', inplace=True)\n",
    "    # Group by 0.25-second intervals and calculate the mean\n",
    "    aggregated_features = processed_flows.groupby(np.ceil(processed_flows.index / .250)).mean(numeric_only=True).fillna(0)\n",
    "    \n",
    "    # Threshold for burst detection\n",
    "    # I = 0.5  # I is in seconds\n",
    "    I = 2\n",
    "\n",
    "    # Initialize variables to store burst series\n",
    "    burst_series = []\n",
    "\n",
    "    # Initialize variables to keep track of burst\n",
    "    burst_start_index = None\n",
    "    burst_sum = 0\n",
    "\n",
    "    # Iterate through the time series data\n",
    "    for i in range(1, len(aggregated_features)):\n",
    "        # Calculate time difference between consecutive points\n",
    "        # time_diff = (aggregated_features.index[i] - aggregated_features.index[i-1]) / 1000  # Convert to seconds\n",
    "        time_diff = (aggregated_features.index[i] - aggregated_features.index[i-1])  # Convert to seconds\n",
    "        \n",
    "        # Check if time difference is less than threshold\n",
    "        if time_diff < I:\n",
    "            # If burst has not started yet, mark the start index\n",
    "            if burst_start_index is None:\n",
    "                burst_start_index = i - 1\n",
    "            \n",
    "            # Add the value of the point to burst sum\n",
    "            burst_sum += aggregated_features.iloc[i]['Length']  # the value of each point in the time series\n",
    "        \n",
    "        else:\n",
    "            # If burst was ongoing, add the burst sum to burst series\n",
    "            if burst_start_index is not None:\n",
    "                burst_series.append(burst_sum)\n",
    "                # Reset burst variables\n",
    "                burst_start_index = None\n",
    "                burst_sum = 0\n",
    "\n",
    "    # If burst was ongoing at the end of the time series, add the burst sum to burst series\n",
    "    if burst_start_index is not None:\n",
    "        burst_series.append(burst_sum)\n",
    "\n",
    "\n",
    "    # Create a custom index based on 250-millisecond intervals\n",
    "    custom_index = pd.timedelta_range(start=0, periods=len(burst_series), freq='250ms')\n",
    "    # Create a Series with burst_series data and custom index\n",
    "    burst_series_with_index = pd.Series(burst_series, index=custom_index)\n",
    "    # Resample the Series into 250-millisecond intervals\n",
    "    aggregated_bursts = burst_series_with_index.resample('250ms').sum().fillna(0)\n",
    "    # print(aggregated_bursts)\n",
    "\n",
    "    # return aggregated_bursts\n",
    "    return aggregated_features\n",
    "\n",
    "# aggFeatures = getBurstSeries(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2454807, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2454807 entries, 0 to 1721851\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   No.          int64  \n",
      " 1   Time         float64\n",
      " 2   Source       object \n",
      " 3   Destination  object \n",
      " 4   Protocol     object \n",
      " 5   Length       int64  \n",
      " 6   Info         object \n",
      " 7   Label        object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 168.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "aggFeatures = getBurstSeries(pcap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggFeatures['Label'] = aggFeatures['Label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggFeatures=aggFeatures.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggFeatures = aggFeatures[np.isfinite(aggFeatures).all(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Label</th>\n",
       "      <th>BPS</th>\n",
       "      <th>PPS</th>\n",
       "      <th>PLEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>420.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.599714e+07</td>\n",
       "      <td>264104.087276</td>\n",
       "      <td>-3.275684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>91.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1.300977e+06</td>\n",
       "      <td>130836.575961</td>\n",
       "      <td>0.093238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.160059e+03</td>\n",
       "      <td>100009.774024</td>\n",
       "      <td>-5.652738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12709</th>\n",
       "      <td>491957.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.968717e+03</td>\n",
       "      <td>55836.615966</td>\n",
       "      <td>-20.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12710</th>\n",
       "      <td>491959.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.171498</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12711</th>\n",
       "      <td>491976.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.638493e+01</td>\n",
       "      <td>83337.950469</td>\n",
       "      <td>-10.036342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12712</th>\n",
       "      <td>491979.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.177783</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12713</th>\n",
       "      <td>491980.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42.072951</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11667 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time      Length  Label           BPS            PPS       PLEN\n",
       "0           0.0   93.000000      2  0.000000e+00       0.000000   0.000000\n",
       "1           1.0  420.888889      1 -4.599714e+07  264104.087276  -3.275684\n",
       "2           2.0   57.000000      2  0.000000e+00       0.000000   0.000000\n",
       "3           5.0   91.444444      1  1.300977e+06  130836.575961   0.093238\n",
       "4           6.0   60.000000      1 -2.160059e+03  100009.774024  -5.652738\n",
       "...         ...         ...    ...           ...            ...        ...\n",
       "12709  491957.0   66.000000      1 -1.968717e+03   55836.615966 -20.317800\n",
       "12710  491959.0   66.000000      1  0.000000e+00       0.171498   0.000000\n",
       "12711  491976.0   61.000000      1  1.638493e+01   83337.950469 -10.036342\n",
       "12712  491979.0   66.000000      1  0.000000e+00       0.177783   0.000000\n",
       "12713  491980.0   66.000000      1  0.000000e+00      42.072951   0.000000\n",
       "\n",
       "[11667 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(aggFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggFeatures = aggFeatures[np.isfinite(aggFeatures).all(1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Label</th>\n",
       "      <th>BPS</th>\n",
       "      <th>PPS</th>\n",
       "      <th>PLEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>420.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.599714e+07</td>\n",
       "      <td>264104.087276</td>\n",
       "      <td>-3.275684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>91.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1.300977e+06</td>\n",
       "      <td>130836.575961</td>\n",
       "      <td>0.093238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.160059e+03</td>\n",
       "      <td>100009.774024</td>\n",
       "      <td>-5.652738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12709</th>\n",
       "      <td>491957.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.968717e+03</td>\n",
       "      <td>55836.615966</td>\n",
       "      <td>-20.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12710</th>\n",
       "      <td>491959.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.171498</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12711</th>\n",
       "      <td>491976.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.638493e+01</td>\n",
       "      <td>83337.950469</td>\n",
       "      <td>-10.036342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12712</th>\n",
       "      <td>491979.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.177783</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12713</th>\n",
       "      <td>491980.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>42.072951</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11667 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time      Length  Label           BPS            PPS       PLEN\n",
       "0           0.0   93.000000      2  0.000000e+00       0.000000   0.000000\n",
       "1           1.0  420.888889      1 -4.599714e+07  264104.087276  -3.275684\n",
       "2           2.0   57.000000      2  0.000000e+00       0.000000   0.000000\n",
       "3           5.0   91.444444      1  1.300977e+06  130836.575961   0.093238\n",
       "4           6.0   60.000000      1 -2.160059e+03  100009.774024  -5.652738\n",
       "...         ...         ...    ...           ...            ...        ...\n",
       "12709  491957.0   66.000000      1 -1.968717e+03   55836.615966 -20.317800\n",
       "12710  491959.0   66.000000      1  0.000000e+00       0.171498   0.000000\n",
       "12711  491976.0   61.000000      1  1.638493e+01   83337.950469 -10.036342\n",
       "12712  491979.0   66.000000      1  0.000000e+00       0.177783   0.000000\n",
       "12713  491980.0   66.000000      1  0.000000e+00      42.072951   0.000000\n",
       "\n",
       "[11667 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aggFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " total numaber of rows  11667\n",
      " total numaber of rows in training 9333\n",
      " total numaber of rows in testing   2334\n"
     ]
    }
   ],
   "source": [
    "total_rows = df.shape[0]\n",
    "print(\" total numaber of rows \" ,total_rows)\n",
    "# Select ratio\n",
    "ratio = 0.80\n",
    "train_size = int(total_rows*ratio)\n",
    "\n",
    "# Split data into test and train\n",
    "train = df[0:train_size]\n",
    "# Remove column name 'A'\n",
    "#train = train.drop(columns=['Time'])\n",
    "total_rows = train.shape[0]\n",
    "print(\" total numaber of rows in training\" ,total_rows)\n",
    "test = df[train_size:]\n",
    "total_rows = test.shape[0]\n",
    "print(\" total numaber of rows in testing  \" ,total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Label</th>\n",
       "      <th>BPS</th>\n",
       "      <th>PPS</th>\n",
       "      <th>PLEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>420.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>-4.599714e+07</td>\n",
       "      <td>264104.087276</td>\n",
       "      <td>-3.275684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>91.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>1.300977e+06</td>\n",
       "      <td>130836.575961</td>\n",
       "      <td>0.093238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.160059e+03</td>\n",
       "      <td>100009.774024</td>\n",
       "      <td>-5.652738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10369</th>\n",
       "      <td>417566.0</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>229.237894</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>417568.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.091939e+01</td>\n",
       "      <td>41671.333092</td>\n",
       "      <td>-9.980981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>417570.0</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.995410e+03</td>\n",
       "      <td>36936.196156</td>\n",
       "      <td>188.705475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>417572.0</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>83333.306971</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>417573.0</td>\n",
       "      <td>1466.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.035579e+02</td>\n",
       "      <td>0.216827</td>\n",
       "      <td>6456.758000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9333 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time       Length  Label           BPS            PPS         PLEN\n",
       "0           0.0    93.000000      2  0.000000e+00       0.000000     0.000000\n",
       "1           1.0   420.888889      1 -4.599714e+07  264104.087276    -3.275684\n",
       "2           2.0    57.000000      2  0.000000e+00       0.000000     0.000000\n",
       "3           5.0    91.444444      1  1.300977e+06  130836.575961     0.093238\n",
       "4           6.0    60.000000      1 -2.160059e+03  100009.774024    -5.652738\n",
       "...         ...          ...    ...           ...            ...          ...\n",
       "10369  417566.0    66.000000      1  0.000000e+00     229.237894     0.000000\n",
       "10370  417568.0    61.000000      1  1.091939e+01   41671.333092    -9.980981\n",
       "10371  417570.0   241.000000      1 -1.995410e+03   36936.196156   188.705475\n",
       "10372  417572.0    62.000000      1  0.000000e+00   83333.306971     0.000000\n",
       "10373  417573.0  1466.000000      1  3.035579e+02       0.216827  6456.758000\n",
       "\n",
       "[9333 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Length</th>\n",
       "      <th>Label</th>\n",
       "      <th>BPS</th>\n",
       "      <th>PPS</th>\n",
       "      <th>PLEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>417574.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1638.766664</td>\n",
       "      <td>56137.498262</td>\n",
       "      <td>-24.408600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10375</th>\n",
       "      <td>417576.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2902.171079</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10376</th>\n",
       "      <td>417587.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20736.846427</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10377</th>\n",
       "      <td>417595.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.161588</td>\n",
       "      <td>0.093982</td>\n",
       "      <td>244.727498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10378</th>\n",
       "      <td>417596.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090969</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12709</th>\n",
       "      <td>491957.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1968.717086</td>\n",
       "      <td>55836.615966</td>\n",
       "      <td>-20.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12710</th>\n",
       "      <td>491959.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171498</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12711</th>\n",
       "      <td>491976.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1</td>\n",
       "      <td>16.384930</td>\n",
       "      <td>83337.950469</td>\n",
       "      <td>-10.036342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12712</th>\n",
       "      <td>491979.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177783</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12713</th>\n",
       "      <td>491980.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.072951</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2334 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Time  Length  Label          BPS           PPS        PLEN\n",
       "10374  417574.0    66.0      1 -1638.766664  56137.498262  -24.408600\n",
       "10375  417576.0    66.0      1     0.000000   2902.171079    0.000000\n",
       "10376  417587.0    66.0      1     0.000000  20736.846427    0.000000\n",
       "10377  417595.0    83.0      1     2.161588      0.093982  244.727498\n",
       "10378  417596.0    60.0      1     0.000000      0.090969    0.000000\n",
       "...         ...     ...    ...          ...           ...         ...\n",
       "12709  491957.0    66.0      1 -1968.717086  55836.615966  -20.317800\n",
       "12710  491959.0    66.0      1     0.000000      0.171498    0.000000\n",
       "12711  491976.0    61.0      1    16.384930  83337.950469  -10.036342\n",
       "12712  491979.0    66.0      1     0.000000      0.177783    0.000000\n",
       "12713  491980.0    66.0      1     0.000000     42.072951    0.000000\n",
       "\n",
       "[2334 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index column\n",
    "train.set_index('Time', inplace=True)\n",
    "test.set_index('Time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9333, 4), (9333, 1))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select feature and target variable\n",
    "X = train.loc[:,train.columns != 'Label']\n",
    "y = train.loc[:,train.columns == 'Label']\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "X= X.to_numpy()\n",
    "y= y.to_numpy()\n",
    " \n",
    "y= y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def getAccuracyMetrics(confusionMatrix ):\n",
    "    print(\" >>>> \")\n",
    "    print(confusionMatrix)\n",
    "    conf_matrix = np.array(confusionMatrix)\n",
    "\n",
    "    # Calculate true positives, false positives, true negatives, false negatives\n",
    "    TP = conf_matrix[1, 1]\n",
    "    FP = conf_matrix[0, 1]\n",
    "    TN = conf_matrix[0, 0]\n",
    "    FN = conf_matrix[1, 0]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = (TP + TN) / np.sum(conf_matrix)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "[[ 4.20888889e+02 -4.59971360e+07  2.64104087e+05 -3.27568356e+00]\n",
      " [ 5.70000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.00000000e+01 -2.16005943e+03  1.00009774e+05 -5.65273800e+00]\n",
      " ...\n",
      " [ 6.10000000e+01  1.09193889e+01  4.16713331e+04 -9.98098100e+00]\n",
      " [ 2.41000000e+02 -1.99541002e+03  3.69361962e+04  1.88705475e+02]\n",
      " [ 1.46600000e+03  3.03557916e+02  2.16827083e-01  6.45675800e+03]]\n",
      "[1 2 1 ... 1 1 1]\n",
      "====\n",
      "[[ 9.30000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 9.14444444e+01  1.30097676e+06  1.30836576e+05  9.32376667e-02]\n",
      " [ 8.07213115e+02 -2.30886495e+07  1.30718527e+05  6.03628285e+01]\n",
      " ...\n",
      " [ 6.60000000e+01  0.00000000e+00  9.76586773e-02  0.00000000e+00]\n",
      " [ 2.41000000e+02 -2.13937525e+03  1.35879508e+05  1.41431903e+03]\n",
      " [ 6.20000000e+01  0.00000000e+00  8.33333070e+04  0.00000000e+00]]\n",
      "[2 1 1 ... 1 1 1]\n",
      "==== > \n",
      "epoch 0  | loss: 0.46297 | train_accuracy: 0.75636 | valid_accuracy: 0.77343 |  0:00:01s\n",
      "epoch 1  | loss: 0.35353 | train_accuracy: 0.7861  | valid_accuracy: 0.80503 |  0:00:03s\n",
      "epoch 2  | loss: 0.33924 | train_accuracy: 0.84329 | valid_accuracy: 0.85753 |  0:00:05s\n",
      "epoch 3  | loss: 0.32716 | train_accuracy: 0.76976 | valid_accuracy: 0.78522 |  0:00:08s\n",
      "epoch 4  | loss: 0.31668 | train_accuracy: 0.76051 | valid_accuracy: 0.77665 |  0:00:09s\n",
      "epoch 5  | loss: 0.31181 | train_accuracy: 0.75891 | valid_accuracy: 0.77665 |  0:00:11s\n",
      "epoch 6  | loss: 0.28602 | train_accuracy: 0.75824 | valid_accuracy: 0.77611 |  0:00:13s\n",
      "epoch 7  | loss: 0.26108 | train_accuracy: 0.75837 | valid_accuracy: 0.77665 |  0:00:15s\n",
      "epoch 8  | loss: 0.23131 | train_accuracy: 0.75837 | valid_accuracy: 0.77665 |  0:00:17s\n",
      "epoch 9  | loss: 0.21376 | train_accuracy: 0.7581  | valid_accuracy: 0.77772 |  0:00:19s\n",
      "epoch 10 | loss: 0.1934  | train_accuracy: 0.76092 | valid_accuracy: 0.77825 |  0:00:22s\n",
      "epoch 11 | loss: 0.19897 | train_accuracy: 0.76025 | valid_accuracy: 0.77933 |  0:00:24s\n",
      "epoch 12 | loss: 0.17987 | train_accuracy: 0.76038 | valid_accuracy: 0.77825 |  0:00:26s\n",
      "epoch 13 | loss: 0.18323 | train_accuracy: 0.76132 | valid_accuracy: 0.77879 |  0:00:28s\n",
      "epoch 14 | loss: 0.17074 | train_accuracy: 0.76226 | valid_accuracy: 0.78147 |  0:00:30s\n",
      "epoch 15 | loss: 0.16871 | train_accuracy: 0.76132 | valid_accuracy: 0.77825 |  0:00:32s\n",
      "epoch 16 | loss: 0.16505 | train_accuracy: 0.76159 | valid_accuracy: 0.77986 |  0:00:34s\n",
      "epoch 17 | loss: 0.16498 | train_accuracy: 0.76172 | valid_accuracy: 0.7804  |  0:00:36s\n",
      "epoch 18 | loss: 0.17379 | train_accuracy: 0.76132 | valid_accuracy: 0.77933 |  0:00:37s\n",
      "epoch 19 | loss: 0.15507 | train_accuracy: 0.76145 | valid_accuracy: 0.77933 |  0:00:39s\n",
      "epoch 20 | loss: 0.15771 | train_accuracy: 0.76159 | valid_accuracy: 0.77986 |  0:00:41s\n",
      "epoch 21 | loss: 0.15575 | train_accuracy: 0.76172 | valid_accuracy: 0.77879 |  0:00:43s\n",
      "epoch 22 | loss: 0.15253 | train_accuracy: 0.76025 | valid_accuracy: 0.77933 |  0:00:45s\n",
      "epoch 23 | loss: 0.15583 | train_accuracy: 0.76092 | valid_accuracy: 0.77986 |  0:00:47s\n",
      "epoch 24 | loss: 0.14486 | train_accuracy: 0.76145 | valid_accuracy: 0.77933 |  0:00:48s\n",
      "epoch 25 | loss: 0.13866 | train_accuracy: 0.76172 | valid_accuracy: 0.77933 |  0:00:50s\n",
      "epoch 26 | loss: 0.13696 | train_accuracy: 0.76172 | valid_accuracy: 0.78147 |  0:00:52s\n",
      "epoch 27 | loss: 0.14336 | train_accuracy: 0.76226 | valid_accuracy: 0.78147 |  0:00:54s\n",
      "epoch 28 | loss: 0.13779 | train_accuracy: 0.76159 | valid_accuracy: 0.77986 |  0:00:55s\n",
      "epoch 29 | loss: 0.13195 | train_accuracy: 0.76212 | valid_accuracy: 0.78093 |  0:00:57s\n",
      "epoch 30 | loss: 0.12734 | train_accuracy: 0.76199 | valid_accuracy: 0.78147 |  0:00:59s\n",
      "epoch 31 | loss: 0.13213 | train_accuracy: 0.88789 | valid_accuracy: 0.89555 |  0:01:01s\n",
      "epoch 32 | loss: 0.12667 | train_accuracy: 0.76293 | valid_accuracy: 0.78147 |  0:01:03s\n",
      "epoch 33 | loss: 0.12857 | train_accuracy: 0.76199 | valid_accuracy: 0.782   |  0:01:04s\n",
      "epoch 34 | loss: 0.12789 | train_accuracy: 0.76199 | valid_accuracy: 0.78147 |  0:01:06s\n",
      "epoch 35 | loss: 0.12521 | train_accuracy: 0.76587 | valid_accuracy: 0.78522 |  0:01:08s\n",
      "epoch 36 | loss: 0.12837 | train_accuracy: 0.76025 | valid_accuracy: 0.77825 |  0:01:10s\n",
      "epoch 37 | loss: 0.12363 | train_accuracy: 0.76145 | valid_accuracy: 0.77986 |  0:01:12s\n",
      "epoch 38 | loss: 0.1199  | train_accuracy: 0.76601 | valid_accuracy: 0.78468 |  0:01:13s\n",
      "epoch 39 | loss: 0.1228  | train_accuracy: 0.76145 | valid_accuracy: 0.78147 |  0:01:15s\n",
      "epoch 40 | loss: 0.11813 | train_accuracy: 0.76185 | valid_accuracy: 0.78254 |  0:01:17s\n",
      "epoch 41 | loss: 0.12415 | train_accuracy: 0.76226 | valid_accuracy: 0.77933 |  0:01:19s\n",
      "epoch 42 | loss: 0.11933 | train_accuracy: 0.76239 | valid_accuracy: 0.77986 |  0:01:21s\n",
      "epoch 43 | loss: 0.11599 | train_accuracy: 0.76266 | valid_accuracy: 0.78093 |  0:01:22s\n",
      "epoch 44 | loss: 0.11615 | train_accuracy: 0.76226 | valid_accuracy: 0.7804  |  0:01:24s\n",
      "epoch 45 | loss: 0.11671 | train_accuracy: 0.76266 | valid_accuracy: 0.78093 |  0:01:26s\n",
      "epoch 46 | loss: 0.12449 | train_accuracy: 0.76226 | valid_accuracy: 0.7804  |  0:01:28s\n",
      "epoch 47 | loss: 0.11247 | train_accuracy: 0.76185 | valid_accuracy: 0.78093 |  0:01:29s\n",
      "epoch 48 | loss: 0.10936 | train_accuracy: 0.76306 | valid_accuracy: 0.78254 |  0:01:31s\n",
      "epoch 49 | loss: 0.1169  | train_accuracy: 0.76306 | valid_accuracy: 0.782   |  0:01:33s\n",
      "epoch 50 | loss: 0.11753 | train_accuracy: 0.82347 | valid_accuracy: 0.83235 |  0:01:35s\n",
      "epoch 51 | loss: 0.11586 | train_accuracy: 0.76226 | valid_accuracy: 0.78093 |  0:01:37s\n",
      "epoch 52 | loss: 0.11271 | train_accuracy: 0.76306 | valid_accuracy: 0.78147 |  0:01:38s\n",
      "epoch 53 | loss: 0.10386 | train_accuracy: 0.76239 | valid_accuracy: 0.7804  |  0:01:40s\n",
      "epoch 54 | loss: 0.10983 | train_accuracy: 0.76306 | valid_accuracy: 0.78307 |  0:01:42s\n",
      "epoch 55 | loss: 0.11502 | train_accuracy: 0.76185 | valid_accuracy: 0.77986 |  0:01:44s\n",
      "epoch 56 | loss: 0.10633 | train_accuracy: 0.76226 | valid_accuracy: 0.7804  |  0:01:46s\n",
      "epoch 57 | loss: 0.11647 | train_accuracy: 0.76252 | valid_accuracy: 0.78307 |  0:01:48s\n",
      "epoch 58 | loss: 0.10623 | train_accuracy: 0.76226 | valid_accuracy: 0.782   |  0:01:49s\n",
      "epoch 59 | loss: 0.10705 | train_accuracy: 0.76266 | valid_accuracy: 0.78147 |  0:01:51s\n",
      "epoch 60 | loss: 0.10985 | train_accuracy: 0.76319 | valid_accuracy: 0.78093 |  0:01:53s\n",
      "epoch 61 | loss: 0.11119 | train_accuracy: 0.76293 | valid_accuracy: 0.78415 |  0:01:55s\n",
      "epoch 62 | loss: 0.1041  | train_accuracy: 0.76185 | valid_accuracy: 0.77879 |  0:01:57s\n",
      "epoch 63 | loss: 0.10373 | train_accuracy: 0.76293 | valid_accuracy: 0.78093 |  0:01:58s\n",
      "epoch 64 | loss: 0.11017 | train_accuracy: 0.76574 | valid_accuracy: 0.78468 |  0:02:00s\n",
      "epoch 65 | loss: 0.11303 | train_accuracy: 0.76333 | valid_accuracy: 0.77986 |  0:02:02s\n",
      "epoch 66 | loss: 0.10836 | train_accuracy: 0.76266 | valid_accuracy: 0.77986 |  0:02:04s\n",
      "epoch 67 | loss: 0.11011 | train_accuracy: 0.76413 | valid_accuracy: 0.78254 |  0:02:06s\n",
      "epoch 68 | loss: 0.10992 | train_accuracy: 0.764   | valid_accuracy: 0.78093 |  0:02:08s\n",
      "epoch 69 | loss: 0.10261 | train_accuracy: 0.76279 | valid_accuracy: 0.77879 |  0:02:10s\n",
      "epoch 70 | loss: 0.10279 | train_accuracy: 0.76386 | valid_accuracy: 0.78093 |  0:02:12s\n",
      "epoch 71 | loss: 0.09905 | train_accuracy: 0.76266 | valid_accuracy: 0.7804  |  0:02:14s\n",
      "epoch 72 | loss: 0.10684 | train_accuracy: 0.76507 | valid_accuracy: 0.78307 |  0:02:15s\n",
      "epoch 73 | loss: 0.10425 | train_accuracy: 0.76226 | valid_accuracy: 0.77933 |  0:02:17s\n",
      "epoch 74 | loss: 0.10486 | train_accuracy: 0.76306 | valid_accuracy: 0.78093 |  0:02:19s\n",
      "epoch 75 | loss: 0.10502 | train_accuracy: 0.76319 | valid_accuracy: 0.77879 |  0:02:21s\n",
      "epoch 76 | loss: 0.10097 | train_accuracy: 0.76359 | valid_accuracy: 0.78093 |  0:02:22s\n",
      "epoch 77 | loss: 0.10363 | train_accuracy: 0.764   | valid_accuracy: 0.78093 |  0:02:24s\n",
      "epoch 78 | loss: 0.10349 | train_accuracy: 0.76266 | valid_accuracy: 0.77933 |  0:02:26s\n",
      "epoch 79 | loss: 0.10515 | train_accuracy: 0.76212 | valid_accuracy: 0.77933 |  0:02:28s\n",
      "epoch 80 | loss: 0.09879 | train_accuracy: 0.76319 | valid_accuracy: 0.78307 |  0:02:30s\n",
      "epoch 81 | loss: 0.11339 | train_accuracy: 0.76333 | valid_accuracy: 0.78147 |  0:02:32s\n",
      "epoch 82 | loss: 0.10723 | train_accuracy: 0.76413 | valid_accuracy: 0.782   |  0:02:34s\n",
      "epoch 83 | loss: 0.09985 | train_accuracy: 0.76346 | valid_accuracy: 0.78254 |  0:02:35s\n",
      "epoch 84 | loss: 0.09611 | train_accuracy: 0.76333 | valid_accuracy: 0.78254 |  0:02:37s\n",
      "epoch 85 | loss: 0.10404 | train_accuracy: 0.76426 | valid_accuracy: 0.78093 |  0:02:39s\n",
      "epoch 86 | loss: 0.10799 | train_accuracy: 0.76346 | valid_accuracy: 0.78147 |  0:02:41s\n",
      "epoch 87 | loss: 0.10112 | train_accuracy: 0.76306 | valid_accuracy: 0.7804  |  0:02:42s\n",
      "epoch 88 | loss: 0.10009 | train_accuracy: 0.76373 | valid_accuracy: 0.78147 |  0:02:44s\n",
      "epoch 89 | loss: 0.10178 | train_accuracy: 0.76426 | valid_accuracy: 0.78147 |  0:02:46s\n",
      "epoch 90 | loss: 0.10013 | train_accuracy: 0.76333 | valid_accuracy: 0.78147 |  0:02:48s\n",
      "epoch 91 | loss: 0.10057 | train_accuracy: 0.76266 | valid_accuracy: 0.7804  |  0:02:50s\n",
      "epoch 92 | loss: 0.10762 | train_accuracy: 0.76306 | valid_accuracy: 0.78093 |  0:02:51s\n",
      "epoch 93 | loss: 0.10079 | train_accuracy: 0.76306 | valid_accuracy: 0.7804  |  0:02:54s\n",
      "epoch 94 | loss: 0.10098 | train_accuracy: 0.76359 | valid_accuracy: 0.7804  |  0:02:56s\n",
      "epoch 95 | loss: 0.1039  | train_accuracy: 0.76346 | valid_accuracy: 0.78147 |  0:02:58s\n",
      "epoch 96 | loss: 0.09815 | train_accuracy: 0.76359 | valid_accuracy: 0.77986 |  0:03:00s\n",
      "epoch 97 | loss: 0.10217 | train_accuracy: 0.76319 | valid_accuracy: 0.78147 |  0:03:02s\n",
      "epoch 98 | loss: 0.10504 | train_accuracy: 0.76306 | valid_accuracy: 0.78147 |  0:03:04s\n",
      "epoch 99 | loss: 0.0961  | train_accuracy: 0.76359 | valid_accuracy: 0.78093 |  0:03:05s\n",
      "epoch 100| loss: 0.10104 | train_accuracy: 0.76333 | valid_accuracy: 0.782   |  0:03:07s\n",
      "epoch 101| loss: 0.0996  | train_accuracy: 0.76306 | valid_accuracy: 0.78093 |  0:03:09s\n",
      "epoch 102| loss: 0.0973  | train_accuracy: 0.76346 | valid_accuracy: 0.78147 |  0:03:11s\n",
      "epoch 103| loss: 0.10109 | train_accuracy: 0.76373 | valid_accuracy: 0.7804  |  0:03:13s\n",
      "epoch 104| loss: 0.10032 | train_accuracy: 0.76359 | valid_accuracy: 0.78093 |  0:03:15s\n",
      "epoch 105| loss: 0.09719 | train_accuracy: 0.76346 | valid_accuracy: 0.78093 |  0:03:16s\n",
      "epoch 106| loss: 0.09825 | train_accuracy: 0.76386 | valid_accuracy: 0.78147 |  0:03:18s\n",
      "epoch 107| loss: 0.10063 | train_accuracy: 0.76359 | valid_accuracy: 0.78147 |  0:03:20s\n",
      "epoch 108| loss: 0.09735 | train_accuracy: 0.76386 | valid_accuracy: 0.7804  |  0:03:22s\n",
      "epoch 109| loss: 0.10171 | train_accuracy: 0.76413 | valid_accuracy: 0.782   |  0:03:24s\n",
      "epoch 110| loss: 0.09839 | train_accuracy: 0.76306 | valid_accuracy: 0.78093 |  0:03:25s\n",
      "epoch 111| loss: 0.09855 | train_accuracy: 0.76373 | valid_accuracy: 0.78093 |  0:03:28s\n",
      "epoch 112| loss: 0.09672 | train_accuracy: 0.76333 | valid_accuracy: 0.782   |  0:03:30s\n",
      "epoch 113| loss: 0.09438 | train_accuracy: 0.76426 | valid_accuracy: 0.782   |  0:03:32s\n",
      "epoch 114| loss: 0.09961 | train_accuracy: 0.764   | valid_accuracy: 0.782   |  0:03:34s\n",
      "epoch 115| loss: 0.09509 | train_accuracy: 0.764   | valid_accuracy: 0.78093 |  0:03:36s\n",
      "epoch 116| loss: 0.0965  | train_accuracy: 0.76346 | valid_accuracy: 0.78147 |  0:03:38s\n",
      "epoch 117| loss: 0.09312 | train_accuracy: 0.76373 | valid_accuracy: 0.78093 |  0:03:40s\n",
      "epoch 118| loss: 0.10711 | train_accuracy: 0.764   | valid_accuracy: 0.782   |  0:03:42s\n",
      "epoch 119| loss: 0.10091 | train_accuracy: 0.76413 | valid_accuracy: 0.78147 |  0:03:44s\n",
      "epoch 120| loss: 0.09881 | train_accuracy: 0.76386 | valid_accuracy: 0.78093 |  0:03:45s\n",
      "epoch 121| loss: 0.09414 | train_accuracy: 0.76359 | valid_accuracy: 0.78147 |  0:03:47s\n",
      "epoch 122| loss: 0.10015 | train_accuracy: 0.76386 | valid_accuracy: 0.78147 |  0:03:49s\n",
      "epoch 123| loss: 0.09889 | train_accuracy: 0.76386 | valid_accuracy: 0.78093 |  0:03:51s\n",
      "epoch 124| loss: 0.09428 | train_accuracy: 0.76426 | valid_accuracy: 0.78147 |  0:03:53s\n",
      "epoch 125| loss: 0.09891 | train_accuracy: 0.76386 | valid_accuracy: 0.78093 |  0:03:55s\n",
      "epoch 126| loss: 0.09545 | train_accuracy: 0.76359 | valid_accuracy: 0.78147 |  0:03:56s\n",
      "epoch 127| loss: 0.09411 | train_accuracy: 0.76359 | valid_accuracy: 0.78093 |  0:03:58s\n",
      "epoch 128| loss: 0.09736 | train_accuracy: 0.76359 | valid_accuracy: 0.78147 |  0:04:00s\n",
      "epoch 129| loss: 0.09682 | train_accuracy: 0.764   | valid_accuracy: 0.78147 |  0:04:02s\n",
      "epoch 130| loss: 0.09854 | train_accuracy: 0.76386 | valid_accuracy: 0.782   |  0:04:04s\n",
      "epoch 131| loss: 0.09414 | train_accuracy: 0.76453 | valid_accuracy: 0.78415 |  0:04:07s\n",
      "\n",
      "Early stopping occurred at epoch 131 with best_epoch = 31 and best_valid_accuracy = 0.89555\n",
      "================================================================\n",
      "Confusion Matrix: \n",
      " [[2122   68]\n",
      " [ 769 4507]]\n",
      "\n",
      " >>>> \n",
      "[[2122   68]\n",
      " [ 769 4507]]\n",
      "Accuracy: 0.8878917760514332\n",
      "Precision: 0.9851366120218579\n",
      "Recall: 0.854245640636846\n",
      "F1 Score: 0.9150340066998275\n",
      "================================================================\n",
      "[[ 9.30000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.20888889e+02 -4.59971360e+07  2.64104087e+05 -3.27568356e+00]\n",
      " [ 5.70000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 2.41000000e+02 -1.99541002e+03  3.69361962e+04  1.88705475e+02]\n",
      " [ 6.20000000e+01  0.00000000e+00  8.33333070e+04  0.00000000e+00]\n",
      " [ 1.46600000e+03  3.03557916e+02  2.16827083e-01  6.45675800e+03]]\n",
      "[2 1 2 ... 1 1 1]\n",
      "====\n",
      "[[ 1.40222222e+02  2.39767188e+02  1.89079083e+00  1.40298567e+01]\n",
      " [ 6.96021739e+02 -4.11760558e+05  1.86258594e+04  2.14039382e+01]\n",
      " [ 8.49496350e+02 -4.36487323e+06  3.67922770e+05 -6.28169803e-01]\n",
      " ...\n",
      " [ 6.00000000e+01  0.00000000e+00  6.24725394e-02  0.00000000e+00]\n",
      " [ 6.60000000e+01  0.00000000e+00  2.29237894e+02  0.00000000e+00]\n",
      " [ 6.10000000e+01  1.09193889e+01  4.16713331e+04 -9.98098100e+00]]\n",
      "[2 1 1 ... 1 1 1]\n",
      "==== > \n",
      "epoch 0  | loss: 0.45792 | train_accuracy: 0.83967 | valid_accuracy: 0.86235 |  0:00:01s\n",
      "epoch 1  | loss: 0.35364 | train_accuracy: 0.764   | valid_accuracy: 0.75522 |  0:00:03s\n",
      "epoch 2  | loss: 0.33929 | train_accuracy: 0.78168 | valid_accuracy: 0.77076 |  0:00:05s\n",
      "epoch 3  | loss: 0.32808 | train_accuracy: 0.7656  | valid_accuracy: 0.75576 |  0:00:07s\n",
      "epoch 4  | loss: 0.3104  | train_accuracy: 0.76547 | valid_accuracy: 0.75522 |  0:00:09s\n",
      "epoch 5  | loss: 0.29468 | train_accuracy: 0.76386 | valid_accuracy: 0.75469 |  0:00:11s\n",
      "epoch 6  | loss: 0.24631 | train_accuracy: 0.76359 | valid_accuracy: 0.75522 |  0:00:12s\n",
      "epoch 7  | loss: 0.24062 | train_accuracy: 0.7656  | valid_accuracy: 0.75522 |  0:00:14s\n",
      "epoch 8  | loss: 0.23207 | train_accuracy: 0.7648  | valid_accuracy: 0.75629 |  0:00:16s\n",
      "epoch 9  | loss: 0.19622 | train_accuracy: 0.76534 | valid_accuracy: 0.75629 |  0:00:18s\n",
      "epoch 10 | loss: 0.20773 | train_accuracy: 0.76641 | valid_accuracy: 0.75629 |  0:00:20s\n",
      "epoch 11 | loss: 0.19055 | train_accuracy: 0.7648  | valid_accuracy: 0.75576 |  0:00:21s\n",
      "epoch 12 | loss: 0.19321 | train_accuracy: 0.76601 | valid_accuracy: 0.75629 |  0:00:23s\n",
      "epoch 13 | loss: 0.18804 | train_accuracy: 0.7656  | valid_accuracy: 0.75415 |  0:00:25s\n",
      "epoch 14 | loss: 0.17699 | train_accuracy: 0.76534 | valid_accuracy: 0.75576 |  0:00:28s\n",
      "epoch 15 | loss: 0.17953 | train_accuracy: 0.76534 | valid_accuracy: 0.75576 |  0:00:29s\n",
      "epoch 16 | loss: 0.165   | train_accuracy: 0.7648  | valid_accuracy: 0.75522 |  0:00:31s\n",
      "epoch 17 | loss: 0.17186 | train_accuracy: 0.76493 | valid_accuracy: 0.75522 |  0:00:33s\n",
      "epoch 18 | loss: 0.16787 | train_accuracy: 0.76694 | valid_accuracy: 0.75576 |  0:00:35s\n",
      "epoch 19 | loss: 0.17096 | train_accuracy: 0.76721 | valid_accuracy: 0.75576 |  0:00:37s\n",
      "epoch 20 | loss: 0.16409 | train_accuracy: 0.76788 | valid_accuracy: 0.75576 |  0:00:38s\n",
      "epoch 21 | loss: 0.16982 | train_accuracy: 0.76868 | valid_accuracy: 0.75522 |  0:00:40s\n",
      "epoch 22 | loss: 0.15413 | train_accuracy: 0.76855 | valid_accuracy: 0.75629 |  0:00:42s\n",
      "epoch 23 | loss: 0.16706 | train_accuracy: 0.76842 | valid_accuracy: 0.75522 |  0:00:44s\n",
      "epoch 24 | loss: 0.15787 | train_accuracy: 0.76654 | valid_accuracy: 0.75469 |  0:00:45s\n",
      "epoch 25 | loss: 0.15358 | train_accuracy: 0.76654 | valid_accuracy: 0.75415 |  0:00:47s\n",
      "epoch 26 | loss: 0.14741 | train_accuracy: 0.76668 | valid_accuracy: 0.75522 |  0:00:50s\n",
      "epoch 27 | loss: 0.15885 | train_accuracy: 0.76842 | valid_accuracy: 0.75522 |  0:00:51s\n",
      "epoch 28 | loss: 0.14412 | train_accuracy: 0.76694 | valid_accuracy: 0.75469 |  0:00:53s\n",
      "epoch 29 | loss: 0.15582 | train_accuracy: 0.82882 | valid_accuracy: 0.81307 |  0:00:55s\n",
      "epoch 30 | loss: 0.14434 | train_accuracy: 0.76694 | valid_accuracy: 0.75362 |  0:00:57s\n",
      "epoch 31 | loss: 0.14404 | train_accuracy: 0.76641 | valid_accuracy: 0.75362 |  0:00:59s\n",
      "epoch 32 | loss: 0.13976 | train_accuracy: 0.76882 | valid_accuracy: 0.75362 |  0:01:01s\n",
      "epoch 33 | loss: 0.13043 | train_accuracy: 0.76815 | valid_accuracy: 0.75308 |  0:01:03s\n",
      "epoch 34 | loss: 0.13114 | train_accuracy: 0.76641 | valid_accuracy: 0.75308 |  0:01:05s\n",
      "epoch 35 | loss: 0.13261 | train_accuracy: 0.96049 | valid_accuracy: 0.96036 |  0:01:07s\n",
      "epoch 36 | loss: 0.13264 | train_accuracy: 0.76668 | valid_accuracy: 0.75415 |  0:01:09s\n",
      "epoch 37 | loss: 0.13068 | train_accuracy: 0.76735 | valid_accuracy: 0.75308 |  0:01:10s\n",
      "epoch 38 | loss: 0.13231 | train_accuracy: 0.76614 | valid_accuracy: 0.75415 |  0:01:12s\n",
      "epoch 39 | loss: 0.13054 | train_accuracy: 0.82856 | valid_accuracy: 0.81468 |  0:01:14s\n",
      "epoch 40 | loss: 0.12814 | train_accuracy: 0.76627 | valid_accuracy: 0.75415 |  0:01:16s\n",
      "epoch 41 | loss: 0.12592 | train_accuracy: 0.76694 | valid_accuracy: 0.75308 |  0:01:18s\n",
      "epoch 42 | loss: 0.12369 | train_accuracy: 0.76721 | valid_accuracy: 0.75362 |  0:01:20s\n",
      "epoch 43 | loss: 0.12922 | train_accuracy: 0.76641 | valid_accuracy: 0.75362 |  0:01:21s\n",
      "epoch 44 | loss: 0.1202  | train_accuracy: 0.82494 | valid_accuracy: 0.80878 |  0:01:23s\n",
      "epoch 45 | loss: 0.12538 | train_accuracy: 0.76721 | valid_accuracy: 0.75362 |  0:01:25s\n",
      "epoch 46 | loss: 0.12452 | train_accuracy: 0.76614 | valid_accuracy: 0.75362 |  0:01:27s\n",
      "epoch 47 | loss: 0.1172  | train_accuracy: 0.76748 | valid_accuracy: 0.75308 |  0:01:29s\n",
      "epoch 48 | loss: 0.12073 | train_accuracy: 0.76654 | valid_accuracy: 0.75415 |  0:01:31s\n",
      "epoch 49 | loss: 0.12084 | train_accuracy: 0.82789 | valid_accuracy: 0.81468 |  0:01:33s\n",
      "epoch 50 | loss: 0.12018 | train_accuracy: 0.76775 | valid_accuracy: 0.75469 |  0:01:35s\n",
      "epoch 51 | loss: 0.12192 | train_accuracy: 0.82789 | valid_accuracy: 0.81468 |  0:01:37s\n",
      "epoch 52 | loss: 0.11368 | train_accuracy: 0.76708 | valid_accuracy: 0.75522 |  0:01:38s\n",
      "epoch 53 | loss: 0.11578 | train_accuracy: 0.82923 | valid_accuracy: 0.81307 |  0:01:40s\n",
      "epoch 54 | loss: 0.11272 | train_accuracy: 0.76681 | valid_accuracy: 0.75469 |  0:01:42s\n",
      "epoch 55 | loss: 0.11919 | train_accuracy: 0.76868 | valid_accuracy: 0.75522 |  0:01:44s\n",
      "epoch 56 | loss: 0.1142  | train_accuracy: 0.76828 | valid_accuracy: 0.75362 |  0:01:46s\n",
      "epoch 57 | loss: 0.11408 | train_accuracy: 0.76868 | valid_accuracy: 0.75415 |  0:01:49s\n",
      "epoch 58 | loss: 0.11886 | train_accuracy: 0.77096 | valid_accuracy: 0.75951 |  0:01:50s\n",
      "epoch 59 | loss: 0.11064 | train_accuracy: 0.95848 | valid_accuracy: 0.95929 |  0:01:52s\n",
      "epoch 60 | loss: 0.11728 | train_accuracy: 0.76721 | valid_accuracy: 0.75362 |  0:01:54s\n",
      "epoch 61 | loss: 0.11385 | train_accuracy: 0.82802 | valid_accuracy: 0.8136  |  0:01:56s\n",
      "epoch 62 | loss: 0.11511 | train_accuracy: 0.91039 | valid_accuracy: 0.90359 |  0:01:58s\n",
      "epoch 63 | loss: 0.11275 | train_accuracy: 0.91669 | valid_accuracy: 0.91162 |  0:02:00s\n",
      "epoch 64 | loss: 0.11289 | train_accuracy: 0.96705 | valid_accuracy: 0.96679 |  0:02:02s\n",
      "epoch 65 | loss: 0.11771 | train_accuracy: 0.88977 | valid_accuracy: 0.88645 |  0:02:03s\n",
      "epoch 66 | loss: 0.10417 | train_accuracy: 0.77177 | valid_accuracy: 0.76004 |  0:02:05s\n",
      "epoch 67 | loss: 0.111   | train_accuracy: 0.77069 | valid_accuracy: 0.75897 |  0:02:07s\n",
      "epoch 68 | loss: 0.11841 | train_accuracy: 0.76868 | valid_accuracy: 0.75415 |  0:02:09s\n",
      "epoch 69 | loss: 0.11366 | train_accuracy: 0.96732 | valid_accuracy: 0.96786 |  0:02:11s\n",
      "epoch 70 | loss: 0.11481 | train_accuracy: 0.76842 | valid_accuracy: 0.75469 |  0:02:12s\n",
      "epoch 71 | loss: 0.10749 | train_accuracy: 0.76855 | valid_accuracy: 0.75362 |  0:02:14s\n",
      "epoch 72 | loss: 0.11203 | train_accuracy: 0.76802 | valid_accuracy: 0.75415 |  0:02:16s\n",
      "epoch 73 | loss: 0.11161 | train_accuracy: 0.76775 | valid_accuracy: 0.75522 |  0:02:18s\n",
      "epoch 74 | loss: 0.10377 | train_accuracy: 0.82775 | valid_accuracy: 0.8136  |  0:02:20s\n",
      "epoch 75 | loss: 0.10733 | train_accuracy: 0.82856 | valid_accuracy: 0.81414 |  0:02:22s\n",
      "epoch 76 | loss: 0.10915 | train_accuracy: 0.77043 | valid_accuracy: 0.75897 |  0:02:24s\n",
      "epoch 77 | loss: 0.10464 | train_accuracy: 0.77029 | valid_accuracy: 0.75844 |  0:02:26s\n",
      "epoch 78 | loss: 0.1048  | train_accuracy: 0.96705 | valid_accuracy: 0.9684  |  0:02:28s\n",
      "epoch 79 | loss: 0.10845 | train_accuracy: 0.89312 | valid_accuracy: 0.88645 |  0:02:29s\n",
      "epoch 80 | loss: 0.10801 | train_accuracy: 0.77043 | valid_accuracy: 0.75897 |  0:02:31s\n",
      "epoch 81 | loss: 0.10429 | train_accuracy: 0.91294 | valid_accuracy: 0.9068  |  0:02:33s\n",
      "epoch 82 | loss: 0.10718 | train_accuracy: 0.77029 | valid_accuracy: 0.75736 |  0:02:35s\n",
      "epoch 83 | loss: 0.11004 | train_accuracy: 0.912   | valid_accuracy: 0.90412 |  0:02:37s\n",
      "epoch 84 | loss: 0.1066  | train_accuracy: 0.82735 | valid_accuracy: 0.81307 |  0:02:39s\n",
      "epoch 85 | loss: 0.10883 | train_accuracy: 0.76641 | valid_accuracy: 0.75362 |  0:02:41s\n",
      "epoch 86 | loss: 0.10723 | train_accuracy: 0.82467 | valid_accuracy: 0.80878 |  0:02:43s\n",
      "epoch 87 | loss: 0.10335 | train_accuracy: 0.82615 | valid_accuracy: 0.81093 |  0:02:45s\n",
      "epoch 88 | loss: 0.10498 | train_accuracy: 0.82521 | valid_accuracy: 0.80878 |  0:02:47s\n",
      "epoch 89 | loss: 0.10311 | train_accuracy: 0.77029 | valid_accuracy: 0.7579  |  0:02:48s\n",
      "epoch 90 | loss: 0.10371 | train_accuracy: 0.77069 | valid_accuracy: 0.75951 |  0:02:50s\n",
      "epoch 91 | loss: 0.10356 | train_accuracy: 0.96451 | valid_accuracy: 0.96626 |  0:02:52s\n",
      "epoch 92 | loss: 0.10226 | train_accuracy: 0.77016 | valid_accuracy: 0.75844 |  0:02:54s\n",
      "epoch 93 | loss: 0.10895 | train_accuracy: 0.77136 | valid_accuracy: 0.7579  |  0:02:57s\n",
      "epoch 94 | loss: 0.10231 | train_accuracy: 0.83043 | valid_accuracy: 0.81735 |  0:02:58s\n",
      "epoch 95 | loss: 0.09888 | train_accuracy: 0.82748 | valid_accuracy: 0.81253 |  0:03:01s\n",
      "epoch 96 | loss: 0.10374 | train_accuracy: 0.76935 | valid_accuracy: 0.75469 |  0:03:02s\n",
      "epoch 97 | loss: 0.09982 | train_accuracy: 0.82869 | valid_accuracy: 0.81575 |  0:03:04s\n",
      "epoch 98 | loss: 0.10625 | train_accuracy: 0.96491 | valid_accuracy: 0.9684  |  0:03:06s\n",
      "epoch 99 | loss: 0.10073 | train_accuracy: 0.96169 | valid_accuracy: 0.96411 |  0:03:08s\n",
      "epoch 100| loss: 0.10701 | train_accuracy: 0.82775 | valid_accuracy: 0.81414 |  0:03:10s\n",
      "epoch 101| loss: 0.0998  | train_accuracy: 0.77177 | valid_accuracy: 0.75844 |  0:03:12s\n",
      "epoch 102| loss: 0.10569 | train_accuracy: 0.90021 | valid_accuracy: 0.89555 |  0:03:14s\n",
      "epoch 103| loss: 0.10535 | train_accuracy: 0.77029 | valid_accuracy: 0.75897 |  0:03:15s\n",
      "epoch 104| loss: 0.10285 | train_accuracy: 0.90196 | valid_accuracy: 0.8977  |  0:03:17s\n",
      "epoch 105| loss: 0.10391 | train_accuracy: 0.77083 | valid_accuracy: 0.75844 |  0:03:19s\n",
      "epoch 106| loss: 0.09752 | train_accuracy: 0.89379 | valid_accuracy: 0.88966 |  0:03:21s\n",
      "epoch 107| loss: 0.1044  | train_accuracy: 0.77123 | valid_accuracy: 0.7579  |  0:03:23s\n",
      "epoch 108| loss: 0.10019 | train_accuracy: 0.96009 | valid_accuracy: 0.96304 |  0:03:25s\n",
      "epoch 109| loss: 0.10574 | train_accuracy: 0.96451 | valid_accuracy: 0.96572 |  0:03:26s\n",
      "epoch 110| loss: 0.09928 | train_accuracy: 0.77002 | valid_accuracy: 0.75736 |  0:03:28s\n",
      "epoch 111| loss: 0.09592 | train_accuracy: 0.7723  | valid_accuracy: 0.7579  |  0:03:30s\n",
      "epoch 112| loss: 0.1003  | train_accuracy: 0.77123 | valid_accuracy: 0.75951 |  0:03:32s\n",
      "epoch 113| loss: 0.09898 | train_accuracy: 0.77056 | valid_accuracy: 0.7579  |  0:03:34s\n",
      "epoch 114| loss: 0.10202 | train_accuracy: 0.77029 | valid_accuracy: 0.75683 |  0:03:36s\n",
      "epoch 115| loss: 0.09713 | train_accuracy: 0.76976 | valid_accuracy: 0.7579  |  0:03:38s\n",
      "epoch 116| loss: 0.1003  | train_accuracy: 0.76989 | valid_accuracy: 0.75683 |  0:03:40s\n",
      "epoch 117| loss: 0.09951 | train_accuracy: 0.90865 | valid_accuracy: 0.90252 |  0:03:42s\n",
      "epoch 118| loss: 0.10322 | train_accuracy: 0.82695 | valid_accuracy: 0.8136  |  0:03:44s\n",
      "epoch 119| loss: 0.10065 | train_accuracy: 0.77083 | valid_accuracy: 0.75683 |  0:03:46s\n",
      "epoch 120| loss: 0.1043  | train_accuracy: 0.77217 | valid_accuracy: 0.7579  |  0:03:47s\n",
      "epoch 121| loss: 0.10126 | train_accuracy: 0.7711  | valid_accuracy: 0.7579  |  0:03:49s\n",
      "epoch 122| loss: 0.10361 | train_accuracy: 0.76962 | valid_accuracy: 0.75629 |  0:03:51s\n",
      "epoch 123| loss: 0.09407 | train_accuracy: 0.77083 | valid_accuracy: 0.75683 |  0:03:53s\n",
      "epoch 124| loss: 0.09673 | train_accuracy: 0.96035 | valid_accuracy: 0.96144 |  0:03:55s\n",
      "epoch 125| loss: 0.09872 | train_accuracy: 0.77096 | valid_accuracy: 0.75736 |  0:03:56s\n",
      "epoch 126| loss: 0.10348 | train_accuracy: 0.83244 | valid_accuracy: 0.81682 |  0:03:58s\n",
      "epoch 127| loss: 0.09924 | train_accuracy: 0.96518 | valid_accuracy: 0.96733 |  0:04:00s\n",
      "epoch 128| loss: 0.10218 | train_accuracy: 0.90048 | valid_accuracy: 0.89663 |  0:04:02s\n",
      "epoch 129| loss: 0.09592 | train_accuracy: 0.7715  | valid_accuracy: 0.75683 |  0:04:04s\n",
      "epoch 130| loss: 0.10013 | train_accuracy: 0.96437 | valid_accuracy: 0.96358 |  0:04:06s\n",
      "epoch 131| loss: 0.0954  | train_accuracy: 0.77083 | valid_accuracy: 0.75897 |  0:04:08s\n",
      "epoch 132| loss: 0.09704 | train_accuracy: 0.77056 | valid_accuracy: 0.7579  |  0:04:10s\n",
      "epoch 133| loss: 0.09944 | train_accuracy: 0.76802 | valid_accuracy: 0.75308 |  0:04:11s\n",
      "epoch 134| loss: 0.10037 | train_accuracy: 0.82949 | valid_accuracy: 0.81682 |  0:04:13s\n",
      "epoch 135| loss: 0.09401 | train_accuracy: 0.82909 | valid_accuracy: 0.81843 |  0:04:15s\n",
      "epoch 136| loss: 0.09709 | train_accuracy: 0.77056 | valid_accuracy: 0.7579  |  0:04:17s\n",
      "epoch 137| loss: 0.09281 | train_accuracy: 0.89003 | valid_accuracy: 0.88538 |  0:04:19s\n",
      "epoch 138| loss: 0.09458 | train_accuracy: 0.77016 | valid_accuracy: 0.75683 |  0:04:21s\n",
      "epoch 139| loss: 0.09797 | train_accuracy: 0.7719  | valid_accuracy: 0.76004 |  0:04:23s\n",
      "epoch 140| loss: 0.10142 | train_accuracy: 0.77056 | valid_accuracy: 0.75897 |  0:04:25s\n",
      "epoch 141| loss: 0.09431 | train_accuracy: 0.77163 | valid_accuracy: 0.75736 |  0:04:27s\n",
      "epoch 142| loss: 0.09472 | train_accuracy: 0.77083 | valid_accuracy: 0.75736 |  0:04:29s\n",
      "epoch 143| loss: 0.09503 | train_accuracy: 0.82722 | valid_accuracy: 0.812   |  0:04:30s\n",
      "epoch 144| loss: 0.09568 | train_accuracy: 0.96491 | valid_accuracy: 0.96411 |  0:04:33s\n",
      "epoch 145| loss: 0.0991  | train_accuracy: 0.77043 | valid_accuracy: 0.75736 |  0:04:35s\n",
      "epoch 146| loss: 0.09576 | train_accuracy: 0.77043 | valid_accuracy: 0.7579  |  0:04:37s\n",
      "epoch 147| loss: 0.09336 | train_accuracy: 0.7711  | valid_accuracy: 0.75844 |  0:04:39s\n",
      "epoch 148| loss: 0.09864 | train_accuracy: 0.77096 | valid_accuracy: 0.7579  |  0:04:41s\n",
      "epoch 149| loss: 0.09718 | train_accuracy: 0.76708 | valid_accuracy: 0.75362 |  0:04:42s\n",
      "epoch 150| loss: 0.09802 | train_accuracy: 0.96343 | valid_accuracy: 0.96411 |  0:04:44s\n",
      "epoch 151| loss: 0.09727 | train_accuracy: 0.77163 | valid_accuracy: 0.7579  |  0:04:46s\n",
      "epoch 152| loss: 0.09625 | train_accuracy: 0.7719  | valid_accuracy: 0.75897 |  0:04:48s\n",
      "epoch 153| loss: 0.09346 | train_accuracy: 0.77056 | valid_accuracy: 0.75736 |  0:04:50s\n",
      "epoch 154| loss: 0.09668 | train_accuracy: 0.77069 | valid_accuracy: 0.7579  |  0:04:52s\n",
      "epoch 155| loss: 0.09589 | train_accuracy: 0.76989 | valid_accuracy: 0.75897 |  0:04:54s\n",
      "epoch 156| loss: 0.09564 | train_accuracy: 0.82615 | valid_accuracy: 0.812   |  0:04:56s\n",
      "epoch 157| loss: 0.09092 | train_accuracy: 0.76882 | valid_accuracy: 0.75308 |  0:04:58s\n",
      "epoch 158| loss: 0.0925  | train_accuracy: 0.8236  | valid_accuracy: 0.80986 |  0:05:00s\n",
      "epoch 159| loss: 0.0957  | train_accuracy: 0.77136 | valid_accuracy: 0.75897 |  0:05:01s\n",
      "epoch 160| loss: 0.09398 | train_accuracy: 0.89486 | valid_accuracy: 0.89073 |  0:05:03s\n",
      "epoch 161| loss: 0.09372 | train_accuracy: 0.82467 | valid_accuracy: 0.81093 |  0:05:05s\n",
      "epoch 162| loss: 0.09978 | train_accuracy: 0.77096 | valid_accuracy: 0.76004 |  0:05:07s\n",
      "epoch 163| loss: 0.09458 | train_accuracy: 0.77069 | valid_accuracy: 0.75951 |  0:05:09s\n",
      "epoch 164| loss: 0.09409 | train_accuracy: 0.77016 | valid_accuracy: 0.75844 |  0:05:11s\n",
      "epoch 165| loss: 0.09266 | train_accuracy: 0.77083 | valid_accuracy: 0.75844 |  0:05:13s\n",
      "epoch 166| loss: 0.09625 | train_accuracy: 0.82829 | valid_accuracy: 0.8136  |  0:05:14s\n",
      "epoch 167| loss: 0.09431 | train_accuracy: 0.96437 | valid_accuracy: 0.96626 |  0:05:16s\n",
      "epoch 168| loss: 0.09474 | train_accuracy: 0.77069 | valid_accuracy: 0.75844 |  0:05:18s\n",
      "epoch 169| loss: 0.09983 | train_accuracy: 0.77096 | valid_accuracy: 0.75844 |  0:05:20s\n",
      "epoch 170| loss: 0.10002 | train_accuracy: 0.77056 | valid_accuracy: 0.75897 |  0:05:22s\n",
      "epoch 171| loss: 0.09656 | train_accuracy: 0.76641 | valid_accuracy: 0.75469 |  0:05:23s\n",
      "epoch 172| loss: 0.0956  | train_accuracy: 0.76641 | valid_accuracy: 0.75415 |  0:05:25s\n",
      "epoch 173| loss: 0.09481 | train_accuracy: 0.77069 | valid_accuracy: 0.75736 |  0:05:27s\n",
      "epoch 174| loss: 0.08949 | train_accuracy: 0.77069 | valid_accuracy: 0.75844 |  0:05:29s\n",
      "epoch 175| loss: 0.09613 | train_accuracy: 0.83244 | valid_accuracy: 0.81843 |  0:05:31s\n",
      "epoch 176| loss: 0.09327 | train_accuracy: 0.77069 | valid_accuracy: 0.75844 |  0:05:33s\n",
      "epoch 177| loss: 0.09449 | train_accuracy: 0.82494 | valid_accuracy: 0.80986 |  0:05:35s\n",
      "epoch 178| loss: 0.09626 | train_accuracy: 0.91254 | valid_accuracy: 0.90894 |  0:05:37s\n",
      "\n",
      "Early stopping occurred at epoch 178 with best_epoch = 78 and best_valid_accuracy = 0.9684\n",
      "================================================================\n",
      "Confusion Matrix: \n",
      " [[2167   87]\n",
      " [ 159 5053]]\n",
      "\n",
      " >>>> \n",
      "[[2167   87]\n",
      " [ 159 5053]]\n",
      "Accuracy: 0.9670506295204929\n",
      "Precision: 0.9830739299610894\n",
      "Recall: 0.9694934765924789\n",
      "F1 Score: 0.9762364760432767\n",
      "================================================================\n",
      "[[ 9.30000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.20888889e+02 -4.59971360e+07  2.64104087e+05 -3.27568356e+00]\n",
      " [ 5.70000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 2.41000000e+02 -1.99541002e+03  3.69361962e+04  1.88705475e+02]\n",
      " [ 6.20000000e+01  0.00000000e+00  8.33333070e+04  0.00000000e+00]\n",
      " [ 1.46600000e+03  3.03557916e+02  2.16827083e-01  6.45675800e+03]]\n",
      "[2 1 2 ... 1 1 1]\n",
      "====\n",
      "[[ 6.00000000e+01  0.00000000e+00  2.66679405e+05  0.00000000e+00]\n",
      " [ 1.19543564e+03 -2.96886693e+07  1.82563010e+05  3.89648678e-01]\n",
      " [ 7.19545455e+02  8.03737451e+01  3.19012855e+05  2.07630836e+02]\n",
      " ...\n",
      " [ 6.60000000e+01  0.00000000e+00  9.49721731e+00  0.00000000e+00]\n",
      " [ 8.30000000e+01  2.16095020e+00  9.39543566e-02  2.44799718e+02]\n",
      " [ 6.00000000e+01 -4.67878352e+01  1.00001620e+05 -3.61205000e+00]]\n",
      "[1 2 1 ... 1 1 1]\n",
      "==== > \n",
      "epoch 0  | loss: 0.45721 | train_accuracy: 0.76467 | valid_accuracy: 0.7413  |  0:00:01s\n",
      "epoch 1  | loss: 0.34953 | train_accuracy: 0.77645 | valid_accuracy: 0.76111 |  0:00:03s\n",
      "epoch 2  | loss: 0.32877 | train_accuracy: 0.77659 | valid_accuracy: 0.7579  |  0:00:05s\n",
      "epoch 3  | loss: 0.32312 | train_accuracy: 0.84329 | valid_accuracy: 0.8361  |  0:00:07s\n",
      "epoch 4  | loss: 0.31128 | train_accuracy: 0.84289 | valid_accuracy: 0.84467 |  0:00:09s\n",
      "epoch 5  | loss: 0.28404 | train_accuracy: 0.76574 | valid_accuracy: 0.74397 |  0:00:11s\n",
      "epoch 6  | loss: 0.26538 | train_accuracy: 0.76493 | valid_accuracy: 0.74237 |  0:00:13s\n",
      "epoch 7  | loss: 0.23715 | train_accuracy: 0.76694 | valid_accuracy: 0.74397 |  0:00:15s\n",
      "epoch 8  | loss: 0.22452 | train_accuracy: 0.76507 | valid_accuracy: 0.74183 |  0:00:16s\n",
      "epoch 9  | loss: 0.20775 | train_accuracy: 0.76748 | valid_accuracy: 0.74397 |  0:00:18s\n",
      "epoch 10 | loss: 0.20431 | train_accuracy: 0.76694 | valid_accuracy: 0.74451 |  0:00:20s\n",
      "epoch 11 | loss: 0.19131 | train_accuracy: 0.76534 | valid_accuracy: 0.74237 |  0:00:22s\n",
      "epoch 12 | loss: 0.19852 | train_accuracy: 0.76828 | valid_accuracy: 0.74665 |  0:00:24s\n",
      "epoch 13 | loss: 0.18605 | train_accuracy: 0.76828 | valid_accuracy: 0.74558 |  0:00:25s\n",
      "epoch 14 | loss: 0.17624 | train_accuracy: 0.76708 | valid_accuracy: 0.74505 |  0:00:27s\n",
      "epoch 15 | loss: 0.17451 | train_accuracy: 0.76708 | valid_accuracy: 0.74612 |  0:00:29s\n",
      "epoch 16 | loss: 0.17045 | train_accuracy: 0.76788 | valid_accuracy: 0.74612 |  0:00:31s\n",
      "epoch 17 | loss: 0.164   | train_accuracy: 0.76761 | valid_accuracy: 0.74612 |  0:00:33s\n",
      "epoch 18 | loss: 0.17114 | train_accuracy: 0.76802 | valid_accuracy: 0.74612 |  0:00:35s\n",
      "epoch 19 | loss: 0.1625  | train_accuracy: 0.76761 | valid_accuracy: 0.74558 |  0:00:37s\n",
      "epoch 20 | loss: 0.16474 | train_accuracy: 0.76748 | valid_accuracy: 0.74558 |  0:00:39s\n",
      "epoch 21 | loss: 0.15538 | train_accuracy: 0.76761 | valid_accuracy: 0.74612 |  0:00:41s\n",
      "epoch 22 | loss: 0.16078 | train_accuracy: 0.76735 | valid_accuracy: 0.74505 |  0:00:42s\n",
      "epoch 23 | loss: 0.15031 | train_accuracy: 0.76882 | valid_accuracy: 0.74719 |  0:00:44s\n",
      "epoch 24 | loss: 0.16286 | train_accuracy: 0.76842 | valid_accuracy: 0.74719 |  0:00:46s\n",
      "epoch 25 | loss: 0.14957 | train_accuracy: 0.76788 | valid_accuracy: 0.74505 |  0:00:48s\n",
      "epoch 26 | loss: 0.14389 | train_accuracy: 0.76962 | valid_accuracy: 0.74879 |  0:00:50s\n",
      "epoch 27 | loss: 0.14505 | train_accuracy: 0.76788 | valid_accuracy: 0.74451 |  0:00:51s\n",
      "epoch 28 | loss: 0.14281 | train_accuracy: 0.76775 | valid_accuracy: 0.74772 |  0:00:53s\n",
      "epoch 29 | loss: 0.14077 | train_accuracy: 0.76882 | valid_accuracy: 0.74879 |  0:00:57s\n",
      "epoch 30 | loss: 0.13576 | train_accuracy: 0.76882 | valid_accuracy: 0.74879 |  0:00:59s\n",
      "epoch 31 | loss: 0.13829 | train_accuracy: 0.76949 | valid_accuracy: 0.74879 |  0:01:01s\n",
      "epoch 32 | loss: 0.14099 | train_accuracy: 0.76949 | valid_accuracy: 0.74987 |  0:01:06s\n",
      "epoch 33 | loss: 0.13548 | train_accuracy: 0.76989 | valid_accuracy: 0.74987 |  0:01:07s\n",
      "epoch 34 | loss: 0.13207 | train_accuracy: 0.76775 | valid_accuracy: 0.74558 |  0:01:10s\n",
      "epoch 35 | loss: 0.13171 | train_accuracy: 0.76828 | valid_accuracy: 0.74826 |  0:01:12s\n",
      "epoch 36 | loss: 0.13768 | train_accuracy: 0.76802 | valid_accuracy: 0.74933 |  0:01:14s\n",
      "epoch 37 | loss: 0.12862 | train_accuracy: 0.76828 | valid_accuracy: 0.74987 |  0:01:17s\n",
      "epoch 38 | loss: 0.12832 | train_accuracy: 0.76788 | valid_accuracy: 0.74719 |  0:01:18s\n",
      "epoch 39 | loss: 0.13175 | train_accuracy: 0.76909 | valid_accuracy: 0.74719 |  0:01:20s\n",
      "epoch 40 | loss: 0.13258 | train_accuracy: 0.76842 | valid_accuracy: 0.74933 |  0:01:21s\n",
      "epoch 41 | loss: 0.12786 | train_accuracy: 0.76962 | valid_accuracy: 0.74826 |  0:01:23s\n",
      "epoch 42 | loss: 0.13215 | train_accuracy: 0.76949 | valid_accuracy: 0.74933 |  0:01:25s\n",
      "epoch 43 | loss: 0.12533 | train_accuracy: 0.76909 | valid_accuracy: 0.7504  |  0:01:27s\n",
      "epoch 44 | loss: 0.12232 | train_accuracy: 0.76949 | valid_accuracy: 0.74987 |  0:01:29s\n",
      "epoch 45 | loss: 0.12341 | train_accuracy: 0.77083 | valid_accuracy: 0.75201 |  0:01:31s\n",
      "epoch 46 | loss: 0.12794 | train_accuracy: 0.76989 | valid_accuracy: 0.75094 |  0:01:32s\n",
      "epoch 47 | loss: 0.12084 | train_accuracy: 0.76895 | valid_accuracy: 0.74826 |  0:01:34s\n",
      "epoch 48 | loss: 0.11148 | train_accuracy: 0.7719  | valid_accuracy: 0.75362 |  0:01:35s\n",
      "epoch 49 | loss: 0.11147 | train_accuracy: 0.77002 | valid_accuracy: 0.7504  |  0:01:37s\n",
      "epoch 50 | loss: 0.11833 | train_accuracy: 0.76855 | valid_accuracy: 0.7504  |  0:01:38s\n",
      "epoch 51 | loss: 0.12232 | train_accuracy: 0.77029 | valid_accuracy: 0.7504  |  0:01:40s\n",
      "epoch 52 | loss: 0.11686 | train_accuracy: 0.76976 | valid_accuracy: 0.7504  |  0:05:18s\n",
      "epoch 53 | loss: 0.10772 | train_accuracy: 0.77016 | valid_accuracy: 0.74933 |  0:05:21s\n",
      "epoch 54 | loss: 0.10474 | train_accuracy: 0.76949 | valid_accuracy: 0.74933 |  0:05:23s\n",
      "epoch 55 | loss: 0.11137 | train_accuracy: 0.76909 | valid_accuracy: 0.7504  |  0:05:25s\n",
      "epoch 56 | loss: 0.10788 | train_accuracy: 0.77056 | valid_accuracy: 0.7504  |  0:05:27s\n",
      "epoch 57 | loss: 0.1111  | train_accuracy: 0.77029 | valid_accuracy: 0.75201 |  0:05:29s\n",
      "epoch 58 | loss: 0.10729 | train_accuracy: 0.77016 | valid_accuracy: 0.74987 |  0:05:31s\n",
      "epoch 59 | loss: 0.1072  | train_accuracy: 0.76989 | valid_accuracy: 0.75147 |  0:05:33s\n",
      "epoch 60 | loss: 0.11026 | train_accuracy: 0.77002 | valid_accuracy: 0.7504  |  0:05:35s\n",
      "epoch 61 | loss: 0.10746 | train_accuracy: 0.77002 | valid_accuracy: 0.74933 |  0:05:37s\n",
      "epoch 62 | loss: 0.10651 | train_accuracy: 0.77029 | valid_accuracy: 0.7504  |  0:05:39s\n",
      "epoch 63 | loss: 0.10765 | train_accuracy: 0.77016 | valid_accuracy: 0.7504  |  0:05:40s\n",
      "epoch 64 | loss: 0.10237 | train_accuracy: 0.82427 | valid_accuracy: 0.81039 |  0:05:42s\n",
      "epoch 65 | loss: 0.11294 | train_accuracy: 0.77069 | valid_accuracy: 0.75201 |  0:05:44s\n",
      "epoch 66 | loss: 0.10332 | train_accuracy: 0.77136 | valid_accuracy: 0.75308 |  0:05:47s\n",
      "epoch 67 | loss: 0.10911 | train_accuracy: 0.77016 | valid_accuracy: 0.75308 |  0:05:48s\n",
      "epoch 68 | loss: 0.10258 | train_accuracy: 0.77016 | valid_accuracy: 0.75254 |  0:05:50s\n",
      "epoch 69 | loss: 0.10075 | train_accuracy: 0.76962 | valid_accuracy: 0.74826 |  0:05:52s\n",
      "epoch 70 | loss: 0.11014 | train_accuracy: 0.77324 | valid_accuracy: 0.75683 |  0:05:53s\n",
      "epoch 71 | loss: 0.10847 | train_accuracy: 0.76989 | valid_accuracy: 0.7504  |  0:05:55s\n",
      "epoch 72 | loss: 0.10589 | train_accuracy: 0.77377 | valid_accuracy: 0.7579  |  0:05:56s\n",
      "epoch 73 | loss: 0.10574 | train_accuracy: 0.76976 | valid_accuracy: 0.7504  |  0:05:58s\n",
      "epoch 74 | loss: 0.11171 | train_accuracy: 0.77083 | valid_accuracy: 0.75094 |  0:06:00s\n",
      "epoch 75 | loss: 0.10601 | train_accuracy: 0.77016 | valid_accuracy: 0.7504  |  0:06:01s\n",
      "epoch 76 | loss: 0.10286 | train_accuracy: 0.76989 | valid_accuracy: 0.7504  |  0:06:03s\n",
      "epoch 77 | loss: 0.10262 | train_accuracy: 0.77083 | valid_accuracy: 0.75147 |  0:06:04s\n",
      "epoch 78 | loss: 0.11142 | train_accuracy: 0.77002 | valid_accuracy: 0.7504  |  0:06:06s\n",
      "epoch 79 | loss: 0.10168 | train_accuracy: 0.76989 | valid_accuracy: 0.75254 |  0:06:07s\n",
      "epoch 80 | loss: 0.10203 | train_accuracy: 0.7711  | valid_accuracy: 0.75362 |  0:06:09s\n",
      "epoch 81 | loss: 0.09988 | train_accuracy: 0.77083 | valid_accuracy: 0.75415 |  0:06:11s\n",
      "epoch 82 | loss: 0.10532 | train_accuracy: 0.77351 | valid_accuracy: 0.75683 |  0:06:12s\n",
      "epoch 83 | loss: 0.10665 | train_accuracy: 0.77069 | valid_accuracy: 0.75147 |  0:06:14s\n",
      "epoch 84 | loss: 0.1099  | train_accuracy: 0.77511 | valid_accuracy: 0.75844 |  0:06:15s\n",
      "epoch 85 | loss: 0.10076 | train_accuracy: 0.77096 | valid_accuracy: 0.75415 |  0:10:09s\n",
      "epoch 86 | loss: 0.09733 | train_accuracy: 0.77297 | valid_accuracy: 0.75522 |  0:10:11s\n",
      "epoch 87 | loss: 0.09913 | train_accuracy: 0.76976 | valid_accuracy: 0.75094 |  0:10:12s\n",
      "epoch 88 | loss: 0.09639 | train_accuracy: 0.77324 | valid_accuracy: 0.75844 |  0:10:14s\n",
      "epoch 89 | loss: 0.10595 | train_accuracy: 0.76962 | valid_accuracy: 0.75254 |  0:10:15s\n",
      "epoch 90 | loss: 0.09985 | train_accuracy: 0.77096 | valid_accuracy: 0.75415 |  0:10:17s\n",
      "epoch 91 | loss: 0.11528 | train_accuracy: 0.77244 | valid_accuracy: 0.75362 |  0:10:19s\n",
      "epoch 92 | loss: 0.10149 | train_accuracy: 0.77096 | valid_accuracy: 0.75308 |  0:10:20s\n",
      "epoch 93 | loss: 0.10733 | train_accuracy: 0.77029 | valid_accuracy: 0.75308 |  0:10:22s\n",
      "epoch 94 | loss: 0.09643 | train_accuracy: 0.77002 | valid_accuracy: 0.75094 |  0:10:23s\n",
      "epoch 95 | loss: 0.09652 | train_accuracy: 0.77177 | valid_accuracy: 0.75522 |  0:10:25s\n",
      "epoch 96 | loss: 0.094   | train_accuracy: 0.76949 | valid_accuracy: 0.75147 |  0:10:27s\n",
      "epoch 97 | loss: 0.09816 | train_accuracy: 0.77096 | valid_accuracy: 0.75147 |  0:10:29s\n",
      "epoch 98 | loss: 0.10299 | train_accuracy: 0.7711  | valid_accuracy: 0.75254 |  0:10:31s\n",
      "epoch 99 | loss: 0.09998 | train_accuracy: 0.77364 | valid_accuracy: 0.75576 |  0:10:32s\n",
      "epoch 100| loss: 0.09768 | train_accuracy: 0.7711  | valid_accuracy: 0.75308 |  0:10:34s\n",
      "epoch 101| loss: 0.10146 | train_accuracy: 0.7723  | valid_accuracy: 0.75522 |  0:10:36s\n",
      "epoch 102| loss: 0.09745 | train_accuracy: 0.77418 | valid_accuracy: 0.75683 |  0:10:38s\n",
      "epoch 103| loss: 0.1024  | train_accuracy: 0.76855 | valid_accuracy: 0.75094 |  0:10:40s\n",
      "epoch 104| loss: 0.09566 | train_accuracy: 0.77351 | valid_accuracy: 0.7579  |  0:10:41s\n",
      "\n",
      "Early stopping occurred at epoch 104 with best_epoch = 4 and best_valid_accuracy = 0.84467\n",
      "================================================================\n",
      "Confusion Matrix: \n",
      " [[1271  942]\n",
      " [ 231 5022]]\n",
      "\n",
      " >>>> \n",
      "[[1271  942]\n",
      " [ 231 5022]]\n",
      "Accuracy: 0.8428877578355211\n",
      "Precision: 0.8420523138832998\n",
      "Recall: 0.9560251284980011\n",
      "F1 Score: 0.8954265846483017\n",
      "================================================================\n",
      "[[ 9.30000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 4.20888889e+02 -4.59971360e+07  2.64104087e+05 -3.27568356e+00]\n",
      " [ 5.70000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 6.10000000e+01  1.09193889e+01  4.16713331e+04 -9.98098100e+00]\n",
      " [ 2.41000000e+02 -1.99541002e+03  3.69361962e+04  1.88705475e+02]\n",
      " [ 6.20000000e+01  0.00000000e+00  8.33333070e+04  0.00000000e+00]]\n",
      "[2 1 2 ... 1 1 1]\n",
      "====\n",
      "[[ 6.00000000e+01 -1.68669767e+03  1.76432811e+00 -1.35462332e+02]\n",
      " [ 8.90864865e+02 -1.52204024e+06  3.13923053e+04  2.71314674e+01]\n",
      " [ 1.00851969e+03 -1.42158921e+07  1.59837490e+05  1.65012081e-01]\n",
      " ...\n",
      " [ 6.60000000e+01  0.00000000e+00  5.15149782e-01  0.00000000e+00]\n",
      " [ 2.41000000e+02 -6.50554216e+02  1.07196148e+04  4.88713750e+01]\n",
      " [ 1.46600000e+03  3.03557916e+02  2.16827083e-01  6.45675800e+03]]\n",
      "[1 2 1 ... 1 1 1]\n",
      "==== > \n",
      "epoch 0  | loss: 0.45421 | train_accuracy: 0.76644 | valid_accuracy: 0.77974 |  0:00:01s\n",
      "epoch 1  | loss: 0.35411 | train_accuracy: 0.76148 | valid_accuracy: 0.77599 |  0:00:03s\n",
      "epoch 2  | loss: 0.33571 | train_accuracy: 0.79831 | valid_accuracy: 0.80922 |  0:00:05s\n",
      "epoch 3  | loss: 0.32638 | train_accuracy: 0.77099 | valid_accuracy: 0.78349 |  0:00:06s\n",
      "epoch 4  | loss: 0.31676 | train_accuracy: 0.86916 | valid_accuracy: 0.84673 |  0:00:08s\n",
      "epoch 5  | loss: 0.30776 | train_accuracy: 0.76068 | valid_accuracy: 0.77546 |  0:00:09s\n",
      "epoch 6  | loss: 0.27258 | train_accuracy: 0.76001 | valid_accuracy: 0.77117 |  0:00:11s\n",
      "epoch 7  | loss: 0.24192 | train_accuracy: 0.76108 | valid_accuracy: 0.77224 |  0:06:47s\n",
      "epoch 8  | loss: 0.22692 | train_accuracy: 0.75934 | valid_accuracy: 0.77278 |  0:06:49s\n",
      "epoch 9  | loss: 0.21234 | train_accuracy: 0.76175 | valid_accuracy: 0.77438 |  0:06:52s\n",
      "epoch 10 | loss: 0.19452 | train_accuracy: 0.76108 | valid_accuracy: 0.77438 |  0:06:54s\n",
      "epoch 11 | loss: 0.18907 | train_accuracy: 0.76242 | valid_accuracy: 0.77385 |  0:06:57s\n",
      "epoch 12 | loss: 0.1848  | train_accuracy: 0.76135 | valid_accuracy: 0.77492 |  0:06:59s\n",
      "epoch 13 | loss: 0.17995 | train_accuracy: 0.76215 | valid_accuracy: 0.77492 |  0:07:01s\n",
      "epoch 14 | loss: 0.1724  | train_accuracy: 0.76296 | valid_accuracy: 0.77546 |  0:07:03s\n",
      "epoch 15 | loss: 0.17551 | train_accuracy: 0.76229 | valid_accuracy: 0.77546 |  0:07:05s\n",
      "epoch 16 | loss: 0.16488 | train_accuracy: 0.76322 | valid_accuracy: 0.77492 |  0:07:07s\n",
      "epoch 17 | loss: 0.16346 | train_accuracy: 0.76296 | valid_accuracy: 0.77599 |  0:07:09s\n",
      "epoch 18 | loss: 0.16561 | train_accuracy: 0.76202 | valid_accuracy: 0.77492 |  0:07:11s\n",
      "epoch 19 | loss: 0.16222 | train_accuracy: 0.76162 | valid_accuracy: 0.77492 |  0:07:13s\n",
      "epoch 20 | loss: 0.1608  | train_accuracy: 0.76148 | valid_accuracy: 0.77546 |  0:07:15s\n",
      "epoch 21 | loss: 0.16107 | train_accuracy: 0.76108 | valid_accuracy: 0.77385 |  0:07:17s\n",
      "epoch 22 | loss: 0.16015 | train_accuracy: 0.76242 | valid_accuracy: 0.77492 |  0:07:19s\n",
      "epoch 23 | loss: 0.15958 | train_accuracy: 0.75934 | valid_accuracy: 0.77492 |  0:07:20s\n",
      "epoch 24 | loss: 0.15684 | train_accuracy: 0.76175 | valid_accuracy: 0.77546 |  0:07:22s\n",
      "epoch 25 | loss: 0.15163 | train_accuracy: 0.76282 | valid_accuracy: 0.77599 |  0:07:24s\n",
      "epoch 26 | loss: 0.14894 | train_accuracy: 0.76202 | valid_accuracy: 0.77599 |  0:07:26s\n",
      "epoch 27 | loss: 0.14926 | train_accuracy: 0.76189 | valid_accuracy: 0.77438 |  0:07:28s\n",
      "epoch 28 | loss: 0.15828 | train_accuracy: 0.76215 | valid_accuracy: 0.77546 |  0:07:30s\n",
      "epoch 29 | loss: 0.14542 | train_accuracy: 0.76336 | valid_accuracy: 0.77492 |  0:07:31s\n",
      "epoch 30 | loss: 0.14281 | train_accuracy: 0.76242 | valid_accuracy: 0.77653 |  0:07:33s\n",
      "epoch 31 | loss: 0.13747 | train_accuracy: 0.76256 | valid_accuracy: 0.77653 |  0:07:35s\n",
      "epoch 32 | loss: 0.14607 | train_accuracy: 0.76135 | valid_accuracy: 0.77546 |  0:07:37s\n",
      "epoch 33 | loss: 0.14595 | train_accuracy: 0.76322 | valid_accuracy: 0.77492 |  0:07:39s\n",
      "epoch 34 | loss: 0.14816 | train_accuracy: 0.89942 | valid_accuracy: 0.9089  |  0:07:41s\n",
      "epoch 35 | loss: 0.14481 | train_accuracy: 0.76229 | valid_accuracy: 0.77599 |  0:07:43s\n",
      "epoch 36 | loss: 0.14019 | train_accuracy: 0.76309 | valid_accuracy: 0.77599 |  0:07:45s\n",
      "epoch 37 | loss: 0.13679 | train_accuracy: 0.76269 | valid_accuracy: 0.77599 |  0:07:48s\n",
      "epoch 38 | loss: 0.13406 | train_accuracy: 0.76376 | valid_accuracy: 0.77599 |  0:07:50s\n",
      "epoch 39 | loss: 0.13811 | train_accuracy: 0.76256 | valid_accuracy: 0.77653 |  0:07:52s\n",
      "epoch 40 | loss: 0.1336  | train_accuracy: 0.76309 | valid_accuracy: 0.77546 |  0:07:54s\n",
      "epoch 41 | loss: 0.13935 | train_accuracy: 0.76215 | valid_accuracy: 0.77546 |  0:07:56s\n",
      "epoch 42 | loss: 0.12758 | train_accuracy: 0.76229 | valid_accuracy: 0.77653 |  0:07:58s\n",
      "epoch 43 | loss: 0.12978 | train_accuracy: 0.76269 | valid_accuracy: 0.77653 |  0:08:00s\n",
      "epoch 44 | loss: 0.13117 | train_accuracy: 0.76229 | valid_accuracy: 0.77653 |  0:08:02s\n",
      "epoch 45 | loss: 0.14069 | train_accuracy: 0.76229 | valid_accuracy: 0.77653 |  0:08:03s\n",
      "epoch 46 | loss: 0.14039 | train_accuracy: 0.76256 | valid_accuracy: 0.77653 |  0:08:05s\n",
      "epoch 47 | loss: 0.13574 | train_accuracy: 0.76282 | valid_accuracy: 0.77653 |  0:08:06s\n",
      "epoch 48 | loss: 0.13206 | train_accuracy: 0.76349 | valid_accuracy: 0.77492 |  0:08:08s\n",
      "epoch 49 | loss: 0.12695 | train_accuracy: 0.76389 | valid_accuracy: 0.77867 |  0:08:10s\n",
      "epoch 50 | loss: 0.12888 | train_accuracy: 0.76416 | valid_accuracy: 0.77814 |  0:08:11s\n",
      "epoch 51 | loss: 0.13016 | train_accuracy: 0.76336 | valid_accuracy: 0.7776  |  0:08:13s\n",
      "epoch 52 | loss: 0.12664 | train_accuracy: 0.76403 | valid_accuracy: 0.7776  |  0:08:15s\n",
      "epoch 53 | loss: 0.13176 | train_accuracy: 0.76309 | valid_accuracy: 0.77706 |  0:08:16s\n",
      "epoch 54 | loss: 0.12403 | train_accuracy: 0.76403 | valid_accuracy: 0.77921 |  0:08:18s\n",
      "epoch 55 | loss: 0.12986 | train_accuracy: 0.76282 | valid_accuracy: 0.77867 |  0:08:19s\n",
      "epoch 56 | loss: 0.12865 | train_accuracy: 0.76349 | valid_accuracy: 0.77867 |  0:08:21s\n",
      "epoch 57 | loss: 0.1307  | train_accuracy: 0.76403 | valid_accuracy: 0.77814 |  0:08:23s\n",
      "epoch 58 | loss: 0.12647 | train_accuracy: 0.76416 | valid_accuracy: 0.77921 |  0:08:24s\n",
      "epoch 59 | loss: 0.122   | train_accuracy: 0.76389 | valid_accuracy: 0.77814 |  0:08:26s\n",
      "epoch 60 | loss: 0.12333 | train_accuracy: 0.76376 | valid_accuracy: 0.77921 |  0:08:28s\n",
      "epoch 61 | loss: 0.12322 | train_accuracy: 0.76403 | valid_accuracy: 0.77867 |  0:08:31s\n",
      "epoch 62 | loss: 0.12448 | train_accuracy: 0.76403 | valid_accuracy: 0.77653 |  0:08:33s\n",
      "epoch 63 | loss: 0.1244  | train_accuracy: 0.76376 | valid_accuracy: 0.77814 |  0:08:35s\n",
      "epoch 64 | loss: 0.11744 | train_accuracy: 0.76336 | valid_accuracy: 0.77867 |  0:08:37s\n",
      "epoch 65 | loss: 0.11895 | train_accuracy: 0.76376 | valid_accuracy: 0.77867 |  0:08:39s\n",
      "epoch 66 | loss: 0.12077 | train_accuracy: 0.76416 | valid_accuracy: 0.77867 |  0:08:41s\n",
      "epoch 67 | loss: 0.11675 | train_accuracy: 0.76403 | valid_accuracy: 0.77814 |  0:08:43s\n",
      "epoch 68 | loss: 0.11861 | train_accuracy: 0.76389 | valid_accuracy: 0.77814 |  0:08:44s\n",
      "epoch 69 | loss: 0.11137 | train_accuracy: 0.76349 | valid_accuracy: 0.77814 |  0:08:46s\n",
      "epoch 70 | loss: 0.11845 | train_accuracy: 0.76403 | valid_accuracy: 0.77867 |  0:08:48s\n",
      "epoch 71 | loss: 0.11021 | train_accuracy: 0.7643  | valid_accuracy: 0.7776  |  0:08:50s\n",
      "epoch 72 | loss: 0.1137  | train_accuracy: 0.76403 | valid_accuracy: 0.77706 |  0:08:52s\n",
      "epoch 73 | loss: 0.12046 | train_accuracy: 0.76403 | valid_accuracy: 0.77706 |  0:08:54s\n",
      "epoch 74 | loss: 0.11537 | train_accuracy: 0.76416 | valid_accuracy: 0.7776  |  0:08:56s\n",
      "epoch 75 | loss: 0.11748 | train_accuracy: 0.76403 | valid_accuracy: 0.77867 |  0:08:58s\n",
      "epoch 76 | loss: 0.12119 | train_accuracy: 0.76403 | valid_accuracy: 0.7776  |  0:08:59s\n",
      "epoch 77 | loss: 0.12189 | train_accuracy: 0.76376 | valid_accuracy: 0.77814 |  0:09:01s\n",
      "epoch 78 | loss: 0.12021 | train_accuracy: 0.76416 | valid_accuracy: 0.77706 |  0:09:03s\n",
      "epoch 79 | loss: 0.10898 | train_accuracy: 0.76403 | valid_accuracy: 0.7776  |  0:09:05s\n",
      "epoch 80 | loss: 0.11715 | train_accuracy: 0.7643  | valid_accuracy: 0.77814 |  0:09:06s\n",
      "epoch 81 | loss: 0.10991 | train_accuracy: 0.76403 | valid_accuracy: 0.7776  |  0:09:08s\n",
      "epoch 82 | loss: 0.12315 | train_accuracy: 0.7643  | valid_accuracy: 0.77867 |  0:09:10s\n",
      "epoch 83 | loss: 0.11443 | train_accuracy: 0.76443 | valid_accuracy: 0.77867 |  0:09:12s\n",
      "epoch 84 | loss: 0.12009 | train_accuracy: 0.7643  | valid_accuracy: 0.77867 |  0:09:14s\n",
      "epoch 85 | loss: 0.11488 | train_accuracy: 0.76403 | valid_accuracy: 0.77814 |  0:09:16s\n",
      "epoch 86 | loss: 0.11577 | train_accuracy: 0.76403 | valid_accuracy: 0.77867 |  0:09:18s\n",
      "epoch 87 | loss: 0.10979 | train_accuracy: 0.76403 | valid_accuracy: 0.77814 |  0:09:19s\n",
      "epoch 88 | loss: 0.11095 | train_accuracy: 0.76403 | valid_accuracy: 0.77814 |  0:09:21s\n",
      "epoch 89 | loss: 0.1164  | train_accuracy: 0.7643  | valid_accuracy: 0.7776  |  0:09:23s\n",
      "epoch 90 | loss: 0.12    | train_accuracy: 0.7643  | valid_accuracy: 0.77867 |  0:09:25s\n",
      "epoch 91 | loss: 0.11    | train_accuracy: 0.76456 | valid_accuracy: 0.7776  |  0:09:27s\n",
      "epoch 92 | loss: 0.11655 | train_accuracy: 0.7643  | valid_accuracy: 0.7776  |  0:09:29s\n",
      "epoch 93 | loss: 0.11528 | train_accuracy: 0.76389 | valid_accuracy: 0.77867 |  0:09:31s\n",
      "epoch 94 | loss: 0.11163 | train_accuracy: 0.76403 | valid_accuracy: 0.77814 |  0:09:33s\n",
      "epoch 95 | loss: 0.11819 | train_accuracy: 0.76416 | valid_accuracy: 0.77814 |  0:09:35s\n",
      "epoch 96 | loss: 0.11682 | train_accuracy: 0.76443 | valid_accuracy: 0.7776  |  0:09:37s\n",
      "epoch 97 | loss: 0.11551 | train_accuracy: 0.76363 | valid_accuracy: 0.77814 |  0:09:39s\n",
      "epoch 98 | loss: 0.11984 | train_accuracy: 0.76376 | valid_accuracy: 0.77814 |  0:09:40s\n",
      "epoch 99 | loss: 0.10785 | train_accuracy: 0.76389 | valid_accuracy: 0.7776  |  0:09:42s\n",
      "epoch 100| loss: 0.10614 | train_accuracy: 0.76416 | valid_accuracy: 0.77706 |  0:09:44s\n",
      "epoch 101| loss: 0.11097 | train_accuracy: 0.7647  | valid_accuracy: 0.77814 |  0:09:46s\n",
      "epoch 102| loss: 0.11436 | train_accuracy: 0.76443 | valid_accuracy: 0.77814 |  0:09:48s\n",
      "epoch 103| loss: 0.11076 | train_accuracy: 0.7647  | valid_accuracy: 0.77814 |  0:09:50s\n",
      "epoch 104| loss: 0.12021 | train_accuracy: 0.76416 | valid_accuracy: 0.77814 |  0:09:52s\n",
      "epoch 105| loss: 0.11114 | train_accuracy: 0.7643  | valid_accuracy: 0.7776  |  0:09:54s\n",
      "epoch 106| loss: 0.10192 | train_accuracy: 0.76403 | valid_accuracy: 0.77706 |  0:09:56s\n",
      "epoch 107| loss: 0.11326 | train_accuracy: 0.76416 | valid_accuracy: 0.77867 |  0:09:57s\n",
      "epoch 108| loss: 0.11001 | train_accuracy: 0.76416 | valid_accuracy: 0.7776  |  0:09:59s\n",
      "epoch 109| loss: 0.10732 | train_accuracy: 0.76376 | valid_accuracy: 0.77814 |  0:10:01s\n",
      "epoch 110| loss: 0.11117 | train_accuracy: 0.76376 | valid_accuracy: 0.77814 |  0:10:03s\n",
      "epoch 111| loss: 0.10595 | train_accuracy: 0.7647  | valid_accuracy: 0.77814 |  0:10:05s\n",
      "epoch 112| loss: 0.11271 | train_accuracy: 0.76443 | valid_accuracy: 0.77974 |  0:10:07s\n",
      "epoch 113| loss: 0.10869 | train_accuracy: 0.7647  | valid_accuracy: 0.7776  |  0:10:09s\n",
      "epoch 114| loss: 0.10646 | train_accuracy: 0.7647  | valid_accuracy: 0.77814 |  0:10:10s\n",
      "epoch 115| loss: 0.11529 | train_accuracy: 0.7647  | valid_accuracy: 0.77814 |  0:10:12s\n",
      "epoch 116| loss: 0.1085  | train_accuracy: 0.76456 | valid_accuracy: 0.7776  |  0:10:14s\n",
      "epoch 117| loss: 0.10884 | train_accuracy: 0.76483 | valid_accuracy: 0.77706 |  0:10:16s\n",
      "epoch 118| loss: 0.10772 | train_accuracy: 0.76389 | valid_accuracy: 0.77814 |  0:10:18s\n",
      "epoch 119| loss: 0.10723 | train_accuracy: 0.76403 | valid_accuracy: 0.77974 |  0:10:20s\n",
      "epoch 120| loss: 0.10978 | train_accuracy: 0.76416 | valid_accuracy: 0.78028 |  0:10:22s\n",
      "epoch 121| loss: 0.11022 | train_accuracy: 0.76483 | valid_accuracy: 0.7776  |  0:10:24s\n",
      "epoch 122| loss: 0.10696 | train_accuracy: 0.7651  | valid_accuracy: 0.78028 |  0:10:25s\n",
      "epoch 123| loss: 0.10474 | train_accuracy: 0.76443 | valid_accuracy: 0.77706 |  0:10:27s\n",
      "epoch 124| loss: 0.10733 | train_accuracy: 0.76456 | valid_accuracy: 0.7776  |  0:10:30s\n",
      "epoch 125| loss: 0.11496 | train_accuracy: 0.76456 | valid_accuracy: 0.77814 |  0:10:32s\n",
      "epoch 126| loss: 0.11235 | train_accuracy: 0.76416 | valid_accuracy: 0.7776  |  0:10:34s\n",
      "epoch 127| loss: 0.10736 | train_accuracy: 0.76657 | valid_accuracy: 0.78028 |  0:10:36s\n",
      "epoch 128| loss: 0.10116 | train_accuracy: 0.7643  | valid_accuracy: 0.77706 |  0:10:37s\n",
      "epoch 129| loss: 0.10534 | train_accuracy: 0.7643  | valid_accuracy: 0.7776  |  0:10:39s\n",
      "epoch 130| loss: 0.10773 | train_accuracy: 0.7647  | valid_accuracy: 0.77706 |  0:10:41s\n",
      "epoch 131| loss: 0.10419 | train_accuracy: 0.76389 | valid_accuracy: 0.77706 |  0:10:43s\n",
      "epoch 132| loss: 0.10187 | train_accuracy: 0.76497 | valid_accuracy: 0.77814 |  0:10:45s\n",
      "epoch 133| loss: 0.10637 | train_accuracy: 0.76483 | valid_accuracy: 0.77814 |  0:10:47s\n",
      "epoch 134| loss: 0.10442 | train_accuracy: 0.76403 | valid_accuracy: 0.77814 |  0:10:48s\n",
      "\n",
      "Early stopping occurred at epoch 134 with best_epoch = 34 and best_valid_accuracy = 0.9089\n",
      "================================================================\n",
      "Confusion Matrix: \n",
      " [[2082   89]\n",
      " [ 662 4634]]\n",
      "\n",
      " >>>> \n",
      "[[2082   89]\n",
      " [ 662 4634]]\n",
      "Accuracy: 0.899424132851212\n",
      "Precision: 0.9811560448867246\n",
      "Recall: 0.875\n",
      "F1 Score: 0.925042419403134\n",
      "================================================================\n",
      "[[ 9.30000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 9.14444444e+01  1.30097676e+06  1.30836576e+05  9.32376667e-02]\n",
      " [ 6.00000000e+01 -1.68669767e+03  1.76432811e+00 -1.35462332e+02]\n",
      " ...\n",
      " [ 6.10000000e+01  1.09193889e+01  4.16713331e+04 -9.98098100e+00]\n",
      " [ 6.20000000e+01  0.00000000e+00  8.33333070e+04  0.00000000e+00]\n",
      " [ 1.46600000e+03  3.03557916e+02  2.16827083e-01  6.45675800e+03]]\n",
      "[2 1 1 ... 1 1 1]\n",
      "====\n",
      "[[ 4.20888889e+02 -4.59971360e+07  2.64104087e+05 -3.27568356e+00]\n",
      " [ 5.70000000e+01  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 6.00000000e+01 -2.16005943e+03  1.00009774e+05 -5.65273800e+00]\n",
      " ...\n",
      " [ 6.00000000e+01 -3.23974691e+01  2.50001324e+05 -4.08210900e+00]\n",
      " [ 8.60000000e+01  1.65290233e+00  6.35731667e-02  4.08977582e+02]\n",
      " [ 2.41000000e+02 -1.99541002e+03  3.69361962e+04  1.88705475e+02]]\n",
      "[1 2 1 ... 1 1 1]\n",
      "==== > \n",
      "epoch 0  | loss: 0.45425 | train_accuracy: 0.77086 | valid_accuracy: 0.76902 |  0:00:01s\n",
      "epoch 1  | loss: 0.35518 | train_accuracy: 0.77796 | valid_accuracy: 0.77492 |  0:00:03s\n",
      "epoch 2  | loss: 0.33067 | train_accuracy: 0.7722  | valid_accuracy: 0.76956 |  0:00:05s\n",
      "epoch 3  | loss: 0.31965 | train_accuracy: 0.76376 | valid_accuracy: 0.76259 |  0:00:07s\n",
      "epoch 4  | loss: 0.31641 | train_accuracy: 0.92889 | valid_accuracy: 0.91908 |  0:00:09s\n",
      "epoch 5  | loss: 0.30805 | train_accuracy: 0.76389 | valid_accuracy: 0.76367 |  0:00:10s\n",
      "epoch 6  | loss: 0.28326 | train_accuracy: 0.75934 | valid_accuracy: 0.76206 |  0:00:12s\n",
      "epoch 7  | loss: 0.2636  | train_accuracy: 0.76256 | valid_accuracy: 0.76527 |  0:00:14s\n",
      "epoch 8  | loss: 0.24166 | train_accuracy: 0.76242 | valid_accuracy: 0.76313 |  0:00:16s\n",
      "epoch 9  | loss: 0.22183 | train_accuracy: 0.76041 | valid_accuracy: 0.75884 |  0:00:18s\n",
      "epoch 10 | loss: 0.21816 | train_accuracy: 0.7572  | valid_accuracy: 0.75777 |  0:00:19s\n",
      "epoch 11 | loss: 0.2062  | train_accuracy: 0.76162 | valid_accuracy: 0.76152 |  0:00:21s\n",
      "epoch 12 | loss: 0.19378 | train_accuracy: 0.76162 | valid_accuracy: 0.76259 |  0:00:23s\n",
      "epoch 13 | loss: 0.19735 | train_accuracy: 0.76296 | valid_accuracy: 0.76367 |  0:00:25s\n",
      "epoch 14 | loss: 0.18998 | train_accuracy: 0.76403 | valid_accuracy: 0.76474 |  0:00:27s\n",
      "epoch 15 | loss: 0.18254 | train_accuracy: 0.76336 | valid_accuracy: 0.76206 |  0:00:29s\n",
      "epoch 16 | loss: 0.18317 | train_accuracy: 0.76443 | valid_accuracy: 0.76474 |  0:00:31s\n",
      "epoch 17 | loss: 0.1847  | train_accuracy: 0.76309 | valid_accuracy: 0.76367 |  0:00:32s\n",
      "epoch 18 | loss: 0.18227 | train_accuracy: 0.76523 | valid_accuracy: 0.76635 |  0:00:34s\n",
      "epoch 19 | loss: 0.16565 | train_accuracy: 0.76322 | valid_accuracy: 0.7642  |  0:00:36s\n",
      "epoch 20 | loss: 0.17186 | train_accuracy: 0.90331 | valid_accuracy: 0.91211 |  0:00:38s\n",
      "epoch 21 | loss: 0.15566 | train_accuracy: 0.76389 | valid_accuracy: 0.76635 |  0:00:40s\n",
      "epoch 22 | loss: 0.15639 | train_accuracy: 0.7651  | valid_accuracy: 0.76688 |  0:00:41s\n",
      "epoch 23 | loss: 0.15488 | train_accuracy: 0.77059 | valid_accuracy: 0.76635 |  0:00:43s\n",
      "epoch 24 | loss: 0.15109 | train_accuracy: 0.76269 | valid_accuracy: 0.76313 |  0:00:45s\n",
      "epoch 25 | loss: 0.15536 | train_accuracy: 0.76831 | valid_accuracy: 0.76742 |  0:00:47s\n",
      "epoch 26 | loss: 0.14163 | train_accuracy: 0.76523 | valid_accuracy: 0.76581 |  0:00:49s\n",
      "epoch 27 | loss: 0.15222 | train_accuracy: 0.76564 | valid_accuracy: 0.76635 |  0:00:50s\n",
      "epoch 28 | loss: 0.15706 | train_accuracy: 0.76711 | valid_accuracy: 0.76527 |  0:00:52s\n",
      "epoch 29 | loss: 0.14671 | train_accuracy: 0.76697 | valid_accuracy: 0.76635 |  0:00:54s\n",
      "epoch 30 | loss: 0.13397 | train_accuracy: 0.7659  | valid_accuracy: 0.76474 |  0:00:56s\n",
      "epoch 31 | loss: 0.13462 | train_accuracy: 0.76671 | valid_accuracy: 0.76581 |  0:00:58s\n",
      "epoch 32 | loss: 0.13687 | train_accuracy: 0.76497 | valid_accuracy: 0.76474 |  0:01:00s\n",
      "epoch 33 | loss: 0.13312 | train_accuracy: 0.7651  | valid_accuracy: 0.76474 |  0:01:01s\n",
      "epoch 34 | loss: 0.14792 | train_accuracy: 0.76389 | valid_accuracy: 0.7642  |  0:01:03s\n",
      "epoch 35 | loss: 0.13359 | train_accuracy: 0.76885 | valid_accuracy: 0.76742 |  0:01:05s\n",
      "epoch 36 | loss: 0.12846 | train_accuracy: 0.77072 | valid_accuracy: 0.76742 |  0:01:07s\n",
      "epoch 37 | loss: 0.12492 | train_accuracy: 0.77086 | valid_accuracy: 0.76688 |  0:01:09s\n",
      "epoch 38 | loss: 0.12517 | train_accuracy: 0.77126 | valid_accuracy: 0.76635 |  0:01:10s\n",
      "epoch 39 | loss: 0.12723 | train_accuracy: 0.82068 | valid_accuracy: 0.81886 |  0:01:12s\n",
      "epoch 40 | loss: 0.12739 | train_accuracy: 0.96585 | valid_accuracy: 0.96409 |  0:01:14s\n",
      "epoch 41 | loss: 0.12051 | train_accuracy: 0.77046 | valid_accuracy: 0.76474 |  0:01:16s\n",
      "epoch 42 | loss: 0.11703 | train_accuracy: 0.83179 | valid_accuracy: 0.82637 |  0:01:18s\n",
      "epoch 43 | loss: 0.12288 | train_accuracy: 0.76778 | valid_accuracy: 0.76688 |  0:01:20s\n",
      "epoch 44 | loss: 0.12182 | train_accuracy: 0.77046 | valid_accuracy: 0.76206 |  0:01:22s\n",
      "epoch 45 | loss: 0.11837 | train_accuracy: 0.82818 | valid_accuracy: 0.82583 |  0:01:23s\n",
      "epoch 46 | loss: 0.1149  | train_accuracy: 0.77086 | valid_accuracy: 0.76795 |  0:01:25s\n",
      "epoch 47 | loss: 0.11994 | train_accuracy: 0.83032 | valid_accuracy: 0.82637 |  0:01:27s\n",
      "epoch 48 | loss: 0.11875 | train_accuracy: 0.77153 | valid_accuracy: 0.76527 |  0:01:29s\n",
      "epoch 49 | loss: 0.11619 | train_accuracy: 0.77166 | valid_accuracy: 0.76635 |  0:01:31s\n",
      "epoch 50 | loss: 0.11632 | train_accuracy: 0.96598 | valid_accuracy: 0.96088 |  0:01:33s\n",
      "epoch 51 | loss: 0.10576 | train_accuracy: 0.76939 | valid_accuracy: 0.76313 |  0:01:35s\n",
      "epoch 52 | loss: 0.11028 | train_accuracy: 0.7659  | valid_accuracy: 0.76313 |  0:01:37s\n",
      "epoch 53 | loss: 0.11625 | train_accuracy: 0.7722  | valid_accuracy: 0.76635 |  0:01:38s\n",
      "epoch 54 | loss: 0.11272 | train_accuracy: 0.96813 | valid_accuracy: 0.96195 |  0:01:40s\n",
      "epoch 55 | loss: 0.1105  | train_accuracy: 0.76925 | valid_accuracy: 0.76474 |  0:01:42s\n",
      "epoch 56 | loss: 0.11147 | train_accuracy: 0.76912 | valid_accuracy: 0.76581 |  0:01:44s\n",
      "epoch 57 | loss: 0.11412 | train_accuracy: 0.82242 | valid_accuracy: 0.81779 |  0:01:46s\n",
      "epoch 58 | loss: 0.11534 | train_accuracy: 0.89407 | valid_accuracy: 0.89496 |  0:01:48s\n",
      "epoch 59 | loss: 0.1058  | train_accuracy: 0.96813 | valid_accuracy: 0.96141 |  0:01:49s\n",
      "epoch 60 | loss: 0.11598 | train_accuracy: 0.77126 | valid_accuracy: 0.76527 |  0:01:51s\n",
      "epoch 61 | loss: 0.10998 | train_accuracy: 0.76992 | valid_accuracy: 0.76527 |  0:01:53s\n",
      "epoch 62 | loss: 0.11268 | train_accuracy: 0.77046 | valid_accuracy: 0.7642  |  0:01:55s\n",
      "epoch 63 | loss: 0.10628 | train_accuracy: 0.76939 | valid_accuracy: 0.7642  |  0:01:57s\n",
      "epoch 64 | loss: 0.11266 | train_accuracy: 0.77099 | valid_accuracy: 0.76581 |  0:01:59s\n",
      "epoch 65 | loss: 0.10674 | train_accuracy: 0.77153 | valid_accuracy: 0.76474 |  0:02:00s\n",
      "epoch 66 | loss: 0.11058 | train_accuracy: 0.76992 | valid_accuracy: 0.7642  |  0:02:02s\n",
      "epoch 67 | loss: 0.10707 | train_accuracy: 0.77072 | valid_accuracy: 0.7642  |  0:02:04s\n",
      "epoch 68 | loss: 0.10891 | train_accuracy: 0.76858 | valid_accuracy: 0.76313 |  0:02:06s\n",
      "epoch 69 | loss: 0.10496 | train_accuracy: 0.76979 | valid_accuracy: 0.7642  |  0:02:08s\n",
      "epoch 70 | loss: 0.10683 | train_accuracy: 0.7718  | valid_accuracy: 0.76635 |  0:02:10s\n",
      "epoch 71 | loss: 0.10343 | train_accuracy: 0.77032 | valid_accuracy: 0.76527 |  0:02:12s\n",
      "epoch 72 | loss: 0.09687 | train_accuracy: 0.77193 | valid_accuracy: 0.76527 |  0:02:13s\n",
      "epoch 73 | loss: 0.10694 | train_accuracy: 0.77166 | valid_accuracy: 0.76635 |  0:02:15s\n",
      "epoch 74 | loss: 0.10038 | train_accuracy: 0.77126 | valid_accuracy: 0.76581 |  0:02:17s\n",
      "epoch 75 | loss: 0.10565 | train_accuracy: 0.77099 | valid_accuracy: 0.76581 |  0:02:19s\n",
      "epoch 76 | loss: 0.10258 | train_accuracy: 0.76979 | valid_accuracy: 0.76367 |  0:02:21s\n",
      "epoch 77 | loss: 0.10683 | train_accuracy: 0.77086 | valid_accuracy: 0.76474 |  0:02:22s\n",
      "epoch 78 | loss: 0.10503 | train_accuracy: 0.77059 | valid_accuracy: 0.76581 |  0:02:24s\n",
      "epoch 79 | loss: 0.10136 | train_accuracy: 0.773   | valid_accuracy: 0.76688 |  0:02:26s\n",
      "epoch 80 | loss: 0.09541 | train_accuracy: 0.7718  | valid_accuracy: 0.76474 |  0:02:28s\n",
      "epoch 81 | loss: 0.10015 | train_accuracy: 0.77153 | valid_accuracy: 0.76688 |  0:02:30s\n",
      "epoch 82 | loss: 0.09692 | train_accuracy: 0.77233 | valid_accuracy: 0.76527 |  0:02:32s\n",
      "epoch 83 | loss: 0.09814 | train_accuracy: 0.77086 | valid_accuracy: 0.76527 |  0:02:33s\n",
      "epoch 84 | loss: 0.09847 | train_accuracy: 0.77019 | valid_accuracy: 0.76367 |  0:02:35s\n",
      "epoch 85 | loss: 0.09992 | train_accuracy: 0.76979 | valid_accuracy: 0.76474 |  0:02:37s\n",
      "epoch 86 | loss: 0.1045  | train_accuracy: 0.76845 | valid_accuracy: 0.7642  |  0:02:39s\n",
      "epoch 87 | loss: 0.1036  | train_accuracy: 0.75586 | valid_accuracy: 0.74759 |  0:02:41s\n",
      "epoch 88 | loss: 0.10886 | train_accuracy: 0.76858 | valid_accuracy: 0.76152 |  0:02:43s\n",
      "epoch 89 | loss: 0.09712 | train_accuracy: 0.77139 | valid_accuracy: 0.76527 |  0:02:45s\n",
      "epoch 90 | loss: 0.09737 | train_accuracy: 0.77032 | valid_accuracy: 0.76367 |  0:02:47s\n",
      "epoch 91 | loss: 0.10119 | train_accuracy: 0.82443 | valid_accuracy: 0.81779 |  0:02:49s\n",
      "epoch 92 | loss: 0.10018 | train_accuracy: 0.77032 | valid_accuracy: 0.76367 |  0:02:51s\n",
      "epoch 93 | loss: 0.10687 | train_accuracy: 0.76992 | valid_accuracy: 0.76259 |  0:02:53s\n",
      "epoch 94 | loss: 0.09234 | train_accuracy: 0.77072 | valid_accuracy: 0.76206 |  0:02:54s\n",
      "epoch 95 | loss: 0.09569 | train_accuracy: 0.7718  | valid_accuracy: 0.76474 |  0:02:56s\n",
      "epoch 96 | loss: 0.09691 | train_accuracy: 0.77139 | valid_accuracy: 0.7642  |  0:02:58s\n",
      "epoch 97 | loss: 0.10089 | train_accuracy: 0.77166 | valid_accuracy: 0.76635 |  0:03:00s\n",
      "epoch 98 | loss: 0.1023  | train_accuracy: 0.77099 | valid_accuracy: 0.76688 |  0:03:02s\n",
      "epoch 99 | loss: 0.10401 | train_accuracy: 0.77166 | valid_accuracy: 0.76527 |  0:03:04s\n",
      "epoch 100| loss: 0.09559 | train_accuracy: 0.7718  | valid_accuracy: 0.7642  |  0:03:05s\n",
      "epoch 101| loss: 0.09951 | train_accuracy: 0.77153 | valid_accuracy: 0.76474 |  0:03:07s\n",
      "epoch 102| loss: 0.10397 | train_accuracy: 0.77153 | valid_accuracy: 0.76313 |  0:03:09s\n",
      "epoch 103| loss: 0.09536 | train_accuracy: 0.77086 | valid_accuracy: 0.7642  |  0:03:11s\n",
      "epoch 104| loss: 0.10828 | train_accuracy: 0.75934 | valid_accuracy: 0.74973 |  0:03:13s\n",
      "epoch 105| loss: 0.09971 | train_accuracy: 0.77233 | valid_accuracy: 0.76635 |  0:03:15s\n",
      "epoch 106| loss: 0.10021 | train_accuracy: 0.77126 | valid_accuracy: 0.7642  |  0:03:17s\n",
      "epoch 107| loss: 0.0962  | train_accuracy: 0.77193 | valid_accuracy: 0.7642  |  0:03:19s\n",
      "epoch 108| loss: 0.10123 | train_accuracy: 0.77287 | valid_accuracy: 0.76581 |  0:03:21s\n",
      "epoch 109| loss: 0.09486 | train_accuracy: 0.77113 | valid_accuracy: 0.76259 |  0:03:23s\n",
      "epoch 110| loss: 0.09414 | train_accuracy: 0.77072 | valid_accuracy: 0.76206 |  0:03:25s\n",
      "epoch 111| loss: 0.10384 | train_accuracy: 0.75921 | valid_accuracy: 0.7508  |  0:03:27s\n",
      "epoch 112| loss: 0.09904 | train_accuracy: 0.77153 | valid_accuracy: 0.76527 |  0:03:29s\n",
      "epoch 113| loss: 0.09619 | train_accuracy: 0.77126 | valid_accuracy: 0.7642  |  0:03:31s\n",
      "epoch 114| loss: 0.09265 | train_accuracy: 0.77206 | valid_accuracy: 0.76259 |  0:03:32s\n",
      "epoch 115| loss: 0.09594 | train_accuracy: 0.77113 | valid_accuracy: 0.76527 |  0:03:34s\n",
      "epoch 116| loss: 0.09532 | train_accuracy: 0.7718  | valid_accuracy: 0.76527 |  0:03:36s\n",
      "epoch 117| loss: 0.09761 | train_accuracy: 0.77193 | valid_accuracy: 0.76474 |  0:03:38s\n",
      "epoch 118| loss: 0.09699 | train_accuracy: 0.77247 | valid_accuracy: 0.76581 |  0:03:40s\n",
      "epoch 119| loss: 0.09479 | train_accuracy: 0.77139 | valid_accuracy: 0.7642  |  0:03:42s\n",
      "epoch 120| loss: 0.0905  | train_accuracy: 0.77139 | valid_accuracy: 0.76313 |  0:03:43s\n",
      "epoch 121| loss: 0.09649 | train_accuracy: 0.77099 | valid_accuracy: 0.7642  |  0:03:45s\n",
      "epoch 122| loss: 0.09109 | train_accuracy: 0.77166 | valid_accuracy: 0.7642  |  0:03:47s\n",
      "epoch 123| loss: 0.09405 | train_accuracy: 0.7722  | valid_accuracy: 0.76527 |  0:03:49s\n",
      "epoch 124| loss: 0.09578 | train_accuracy: 0.7726  | valid_accuracy: 0.76474 |  0:03:52s\n",
      "epoch 125| loss: 0.10319 | train_accuracy: 0.82577 | valid_accuracy: 0.81886 |  0:03:54s\n",
      "epoch 126| loss: 0.09456 | train_accuracy: 0.75787 | valid_accuracy: 0.74812 |  0:03:56s\n",
      "epoch 127| loss: 0.09491 | train_accuracy: 0.7722  | valid_accuracy: 0.7642  |  0:03:58s\n",
      "epoch 128| loss: 0.10044 | train_accuracy: 0.83005 | valid_accuracy: 0.82101 |  0:04:00s\n",
      "epoch 129| loss: 0.09466 | train_accuracy: 0.7722  | valid_accuracy: 0.76474 |  0:04:01s\n",
      "epoch 130| loss: 0.09733 | train_accuracy: 0.82885 | valid_accuracy: 0.82047 |  0:04:03s\n",
      "epoch 131| loss: 0.09439 | train_accuracy: 0.7718  | valid_accuracy: 0.76581 |  0:04:06s\n",
      "epoch 132| loss: 0.09139 | train_accuracy: 0.7722  | valid_accuracy: 0.76474 |  0:04:08s\n",
      "epoch 133| loss: 0.09345 | train_accuracy: 0.7722  | valid_accuracy: 0.76581 |  0:04:09s\n",
      "epoch 134| loss: 0.09446 | train_accuracy: 0.83246 | valid_accuracy: 0.82369 |  0:04:11s\n",
      "epoch 135| loss: 0.10329 | train_accuracy: 0.77113 | valid_accuracy: 0.7642  |  0:04:13s\n",
      "epoch 136| loss: 0.09061 | train_accuracy: 0.97134 | valid_accuracy: 0.9657  |  0:04:15s\n",
      "epoch 137| loss: 0.09983 | train_accuracy: 0.77153 | valid_accuracy: 0.7642  |  0:04:17s\n",
      "epoch 138| loss: 0.0928  | train_accuracy: 0.77233 | valid_accuracy: 0.76581 |  0:04:19s\n",
      "epoch 139| loss: 0.0992  | train_accuracy: 0.77072 | valid_accuracy: 0.7642  |  0:04:21s\n",
      "epoch 140| loss: 0.09196 | train_accuracy: 0.77113 | valid_accuracy: 0.76367 |  0:04:23s\n",
      "epoch 141| loss: 0.09266 | train_accuracy: 0.77166 | valid_accuracy: 0.76313 |  0:04:24s\n",
      "epoch 142| loss: 0.09145 | train_accuracy: 0.77046 | valid_accuracy: 0.76259 |  0:04:26s\n",
      "epoch 143| loss: 0.09261 | train_accuracy: 0.76965 | valid_accuracy: 0.76152 |  0:04:28s\n",
      "epoch 144| loss: 0.09964 | train_accuracy: 0.77072 | valid_accuracy: 0.76259 |  0:04:30s\n",
      "epoch 145| loss: 0.09632 | train_accuracy: 0.77019 | valid_accuracy: 0.76206 |  0:04:32s\n",
      "epoch 146| loss: 0.09235 | train_accuracy: 0.77166 | valid_accuracy: 0.76313 |  0:04:33s\n",
      "epoch 147| loss: 0.09137 | train_accuracy: 0.77206 | valid_accuracy: 0.76527 |  0:04:35s\n",
      "epoch 148| loss: 0.09549 | train_accuracy: 0.77046 | valid_accuracy: 0.76259 |  0:04:37s\n",
      "epoch 149| loss: 0.09176 | train_accuracy: 0.77113 | valid_accuracy: 0.76259 |  0:04:39s\n",
      "epoch 150| loss: 0.0909  | train_accuracy: 0.77072 | valid_accuracy: 0.76313 |  0:04:41s\n",
      "epoch 151| loss: 0.09414 | train_accuracy: 0.773   | valid_accuracy: 0.76527 |  0:04:42s\n",
      "epoch 152| loss: 0.09408 | train_accuracy: 0.7722  | valid_accuracy: 0.76527 |  0:04:44s\n",
      "epoch 153| loss: 0.08964 | train_accuracy: 0.77206 | valid_accuracy: 0.76527 |  0:04:46s\n",
      "epoch 154| loss: 0.09001 | train_accuracy: 0.77113 | valid_accuracy: 0.76367 |  0:04:48s\n",
      "epoch 155| loss: 0.09761 | train_accuracy: 0.77126 | valid_accuracy: 0.76367 |  0:04:50s\n",
      "epoch 156| loss: 0.09068 | train_accuracy: 0.77273 | valid_accuracy: 0.7642  |  0:04:52s\n",
      "epoch 157| loss: 0.09223 | train_accuracy: 0.7718  | valid_accuracy: 0.7642  |  0:04:54s\n",
      "epoch 158| loss: 0.09179 | train_accuracy: 0.7726  | valid_accuracy: 0.76635 |  0:04:56s\n",
      "epoch 159| loss: 0.09637 | train_accuracy: 0.77206 | valid_accuracy: 0.76581 |  0:04:58s\n",
      "epoch 160| loss: 0.09661 | train_accuracy: 0.77193 | valid_accuracy: 0.7642  |  0:05:00s\n",
      "epoch 161| loss: 0.08888 | train_accuracy: 0.7726  | valid_accuracy: 0.76581 |  0:05:01s\n",
      "epoch 162| loss: 0.08944 | train_accuracy: 0.7718  | valid_accuracy: 0.76367 |  0:05:04s\n",
      "epoch 163| loss: 0.09514 | train_accuracy: 0.77166 | valid_accuracy: 0.76474 |  0:05:06s\n",
      "epoch 164| loss: 0.09456 | train_accuracy: 0.77247 | valid_accuracy: 0.76527 |  0:05:07s\n",
      "epoch 165| loss: 0.09372 | train_accuracy: 0.77193 | valid_accuracy: 0.76367 |  0:05:09s\n",
      "epoch 166| loss: 0.09622 | train_accuracy: 0.7718  | valid_accuracy: 0.76367 |  0:05:11s\n",
      "epoch 167| loss: 0.09348 | train_accuracy: 0.77166 | valid_accuracy: 0.76367 |  0:05:13s\n",
      "epoch 168| loss: 0.09086 | train_accuracy: 0.77113 | valid_accuracy: 0.76474 |  0:05:15s\n",
      "epoch 169| loss: 0.08709 | train_accuracy: 0.77193 | valid_accuracy: 0.7642  |  0:05:16s\n",
      "epoch 170| loss: 0.09996 | train_accuracy: 0.77247 | valid_accuracy: 0.76527 |  0:05:18s\n",
      "epoch 171| loss: 0.0854  | train_accuracy: 0.7722  | valid_accuracy: 0.76527 |  0:05:20s\n",
      "epoch 172| loss: 0.0938  | train_accuracy: 0.77166 | valid_accuracy: 0.7642  |  0:05:22s\n",
      "epoch 173| loss: 0.09545 | train_accuracy: 0.7718  | valid_accuracy: 0.76367 |  0:05:24s\n",
      "epoch 174| loss: 0.09113 | train_accuracy: 0.77086 | valid_accuracy: 0.76367 |  0:05:26s\n",
      "epoch 175| loss: 0.08833 | train_accuracy: 0.7726  | valid_accuracy: 0.76581 |  0:05:27s\n",
      "epoch 176| loss: 0.09138 | train_accuracy: 0.77233 | valid_accuracy: 0.76527 |  0:05:29s\n",
      "epoch 177| loss: 0.09075 | train_accuracy: 0.77206 | valid_accuracy: 0.76367 |  0:05:31s\n",
      "epoch 178| loss: 0.09301 | train_accuracy: 0.77193 | valid_accuracy: 0.76367 |  0:05:33s\n",
      "epoch 179| loss: 0.08839 | train_accuracy: 0.77247 | valid_accuracy: 0.76527 |  0:05:35s\n",
      "epoch 180| loss: 0.08978 | train_accuracy: 0.7726  | valid_accuracy: 0.76581 |  0:05:37s\n",
      "epoch 181| loss: 0.09379 | train_accuracy: 0.77206 | valid_accuracy: 0.76474 |  0:05:38s\n",
      "epoch 182| loss: 0.09029 | train_accuracy: 0.77153 | valid_accuracy: 0.7642  |  0:05:40s\n",
      "epoch 183| loss: 0.09242 | train_accuracy: 0.77233 | valid_accuracy: 0.76474 |  0:05:42s\n",
      "epoch 184| loss: 0.09004 | train_accuracy: 0.7722  | valid_accuracy: 0.76527 |  0:05:44s\n",
      "epoch 185| loss: 0.09587 | train_accuracy: 0.77287 | valid_accuracy: 0.76474 |  0:05:46s\n",
      "epoch 186| loss: 0.09141 | train_accuracy: 0.77139 | valid_accuracy: 0.76367 |  0:05:48s\n",
      "epoch 187| loss: 0.09007 | train_accuracy: 0.77139 | valid_accuracy: 0.76474 |  0:05:49s\n",
      "epoch 188| loss: 0.08794 | train_accuracy: 0.77273 | valid_accuracy: 0.76527 |  0:05:51s\n",
      "epoch 189| loss: 0.08838 | train_accuracy: 0.7722  | valid_accuracy: 0.76527 |  0:05:53s\n",
      "epoch 190| loss: 0.08799 | train_accuracy: 0.77153 | valid_accuracy: 0.76474 |  0:05:55s\n",
      "epoch 191| loss: 0.09203 | train_accuracy: 0.77247 | valid_accuracy: 0.76527 |  0:05:57s\n",
      "epoch 192| loss: 0.09843 | train_accuracy: 0.77153 | valid_accuracy: 0.7642  |  0:05:59s\n",
      "epoch 193| loss: 0.08922 | train_accuracy: 0.77193 | valid_accuracy: 0.76527 |  0:06:01s\n",
      "epoch 194| loss: 0.09618 | train_accuracy: 0.77314 | valid_accuracy: 0.76527 |  0:06:03s\n",
      "epoch 195| loss: 0.09179 | train_accuracy: 0.7722  | valid_accuracy: 0.76527 |  0:06:05s\n",
      "epoch 196| loss: 0.09097 | train_accuracy: 0.77287 | valid_accuracy: 0.76635 |  0:06:07s\n",
      "epoch 197| loss: 0.09073 | train_accuracy: 0.77247 | valid_accuracy: 0.76635 |  0:06:09s\n",
      "epoch 198| loss: 0.08956 | train_accuracy: 0.77273 | valid_accuracy: 0.76581 |  0:06:11s\n",
      "epoch 199| loss: 0.09419 | train_accuracy: 0.77314 | valid_accuracy: 0.76635 |  0:06:13s\n",
      "epoch 200| loss: 0.09431 | train_accuracy: 0.77247 | valid_accuracy: 0.76527 |  0:06:15s\n",
      "epoch 201| loss: 0.08836 | train_accuracy: 0.7722  | valid_accuracy: 0.76527 |  0:06:16s\n",
      "epoch 202| loss: 0.09381 | train_accuracy: 0.77287 | valid_accuracy: 0.76688 |  0:06:18s\n",
      "epoch 203| loss: 0.08723 | train_accuracy: 0.77273 | valid_accuracy: 0.76635 |  0:06:20s\n",
      "epoch 204| loss: 0.09148 | train_accuracy: 0.77206 | valid_accuracy: 0.76581 |  0:06:22s\n",
      "epoch 205| loss: 0.10272 | train_accuracy: 0.9159  | valid_accuracy: 0.91854 |  0:06:24s\n",
      "epoch 206| loss: 0.08969 | train_accuracy: 0.7722  | valid_accuracy: 0.76527 |  0:06:25s\n",
      "epoch 207| loss: 0.08709 | train_accuracy: 0.77126 | valid_accuracy: 0.76527 |  0:06:27s\n",
      "epoch 208| loss: 0.08909 | train_accuracy: 0.77193 | valid_accuracy: 0.76581 |  0:06:29s\n",
      "epoch 209| loss: 0.08866 | train_accuracy: 0.77233 | valid_accuracy: 0.76581 |  0:06:31s\n",
      "epoch 210| loss: 0.09769 | train_accuracy: 0.77273 | valid_accuracy: 0.76635 |  0:06:33s\n",
      "epoch 211| loss: 0.08723 | train_accuracy: 0.77233 | valid_accuracy: 0.76474 |  0:06:34s\n",
      "epoch 212| loss: 0.09176 | train_accuracy: 0.75948 | valid_accuracy: 0.75188 |  0:06:36s\n",
      "epoch 213| loss: 0.08506 | train_accuracy: 0.7726  | valid_accuracy: 0.76581 |  0:06:38s\n",
      "epoch 214| loss: 0.09561 | train_accuracy: 0.77206 | valid_accuracy: 0.76474 |  0:06:40s\n",
      "epoch 215| loss: 0.08901 | train_accuracy: 0.77287 | valid_accuracy: 0.76581 |  0:06:42s\n",
      "epoch 216| loss: 0.09277 | train_accuracy: 0.89688 | valid_accuracy: 0.8955  |  0:06:43s\n",
      "epoch 217| loss: 0.08722 | train_accuracy: 0.82684 | valid_accuracy: 0.82047 |  0:06:45s\n",
      "epoch 218| loss: 0.08788 | train_accuracy: 0.773   | valid_accuracy: 0.76635 |  0:06:47s\n",
      "epoch 219| loss: 0.08739 | train_accuracy: 0.77233 | valid_accuracy: 0.76581 |  0:06:49s\n",
      "epoch 220| loss: 0.08879 | train_accuracy: 0.77247 | valid_accuracy: 0.76635 |  0:06:51s\n",
      "epoch 221| loss: 0.09089 | train_accuracy: 0.75881 | valid_accuracy: 0.75188 |  0:06:53s\n",
      "epoch 222| loss: 0.08732 | train_accuracy: 0.77206 | valid_accuracy: 0.76527 |  0:06:54s\n",
      "epoch 223| loss: 0.0877  | train_accuracy: 0.7722  | valid_accuracy: 0.76581 |  0:06:56s\n",
      "epoch 224| loss: 0.08682 | train_accuracy: 0.77247 | valid_accuracy: 0.76474 |  0:06:58s\n",
      "epoch 225| loss: 0.09332 | train_accuracy: 0.77287 | valid_accuracy: 0.76635 |  0:07:00s\n",
      "epoch 226| loss: 0.09311 | train_accuracy: 0.7726  | valid_accuracy: 0.76635 |  0:07:02s\n",
      "epoch 227| loss: 0.08969 | train_accuracy: 0.77233 | valid_accuracy: 0.76527 |  0:07:03s\n",
      "epoch 228| loss: 0.09153 | train_accuracy: 0.77193 | valid_accuracy: 0.76527 |  0:07:05s\n",
      "epoch 229| loss: 0.09025 | train_accuracy: 0.77206 | valid_accuracy: 0.76527 |  0:07:07s\n",
      "epoch 230| loss: 0.08935 | train_accuracy: 0.77273 | valid_accuracy: 0.76581 |  0:07:09s\n",
      "epoch 231| loss: 0.08857 | train_accuracy: 0.77287 | valid_accuracy: 0.76635 |  0:07:11s\n",
      "epoch 232| loss: 0.08677 | train_accuracy: 0.77327 | valid_accuracy: 0.76635 |  0:07:13s\n",
      "epoch 233| loss: 0.08988 | train_accuracy: 0.773   | valid_accuracy: 0.76581 |  0:07:14s\n",
      "epoch 234| loss: 0.09633 | train_accuracy: 0.77166 | valid_accuracy: 0.76474 |  0:07:16s\n",
      "epoch 235| loss: 0.08088 | train_accuracy: 0.7722  | valid_accuracy: 0.76527 |  0:07:18s\n",
      "epoch 236| loss: 0.0942  | train_accuracy: 0.77206 | valid_accuracy: 0.76527 |  0:07:20s\n",
      "\n",
      "Early stopping occurred at epoch 236 with best_epoch = 136 and best_valid_accuracy = 0.9657\n",
      "================================================================\n",
      "Confusion Matrix: \n",
      " [[2115   93]\n",
      " [ 121 5138]]\n",
      "\n",
      " >>>> \n",
      "[[2115   93]\n",
      " [ 121 5138]]\n",
      "Accuracy: 0.9713405651533413\n",
      "Precision: 0.9822213725865035\n",
      "Recall: 0.9769918235405971\n",
      "F1 Score: 0.9795996186844614\n"
     ]
    }
   ],
   "source": [
    "# define and train the Tabnet model with cross validation\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "CV_score_array    =[]\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    tb_cls = TabNetClassifier(optimizer_fn=torch.optim.Adam,\n",
    "                       optimizer_params=dict(lr=1e-3),\n",
    "                       scheduler_params={\"step_size\":10, \"gamma\":0.9},\n",
    "                       scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "                       mask_type='entmax' # \"sparsemax\"\n",
    "                       )\n",
    "    print(\"================================================================\")\n",
    "    print(X_train)\n",
    "    print(y_train)\n",
    "    print(\"====\")\n",
    "    print(X_valid)\n",
    "    print(y_valid)\n",
    "    print(\"==== > \")\n",
    "    tb_cls.fit(X_train,y_train,\n",
    "               eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "               eval_name=['train', 'valid'],\n",
    "               eval_metric=['accuracy'],\n",
    "               max_epochs=1000 , patience=100,\n",
    "               batch_size=28, drop_last=False)            \n",
    "    CV_score_array.append(tb_cls.best_cost)\n",
    "\n",
    "    \n",
    "    pred=tb_cls.predict(X_train)\n",
    "    print(\"================================================================\")\n",
    "    # print(classification_report(y_valid, pred))\n",
    "    conf_matrix = confusion_matrix(y_train, pred)\n",
    "    print(f\"Confusion Matrix: \\n {conf_matrix}\\n\")\n",
    "\n",
    "    getAccuracyMetrics(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
